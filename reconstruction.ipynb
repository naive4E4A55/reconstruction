{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca03f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_N  → classify_ABC → A_N\n",
      "B_N  → classify_ABC → B_N and C_N\n",
      "C_N  → classify_ABC → B_N and C_N\n",
      "\n",
      "Comparing two sequences: first_is_B\n",
      "  Mean hub variance of the first segment  = 3.902977e-03\n",
      "  Mean hub variance of the second segment = 7.846020e-03\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# star_network_identify.py\n",
    "# ---------------------------------------------------------------\n",
    "\"\"\"\n",
    "Identify star-like network topologies (A/B/C) from time-series produced by a\n",
    "high-precision coupled map lattice (CML). The workflow is:\n",
    "\n",
    "1) Simulate node dynamics on directed star graphs with high numerical precision.\n",
    "2) Compute node-wise error strengths ‖x_{t+1} - 2 x_t‖ (wrapped on the circle).\n",
    "3) Use a 2-component Gaussian Mixture Model (GMM) to separate hubs vs. leaves.\n",
    "4) With two segments (from B/C candidates), compare hubs' residual variances to\n",
    "   decide whether a segment came from type-B (both hubs fully connected) or\n",
    "   type-C (leaves split across two hubs).\n",
    "\n",
    "Conventions\n",
    "-----------\n",
    "- Adjacency A is binary and directed. A[j, i] = 1 means a directed edge j → i,\n",
    "  i.e., node j contributes to the coupling term of node i.\n",
    "- Trajectories are stored as a NumPy array of shape (N, T_seg), with N nodes\n",
    "  and T_seg time steps after discarding transients.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from decimal import Decimal, getcontext\n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "from typing import Callable, Tuple\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# ---------- Global High Precision Settings ----------\n",
    "getcontext().prec = 200\n",
    "mp.mp.dps = getcontext().prec\n",
    "TWOPI = mp.mpf('6.283185307179586476925286766559')\n",
    "SIGMA_H2 = 0.5  # ∫ h^2(0,y) dm(y)  (kept for reference; not used directly)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  I. High-Precision Network System (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "class GraphSystemDecimal:\n",
    "    \"\"\"\n",
    "    Coupled map lattice on a directed graph with high-precision arithmetic.\n",
    "\n",
    "    Each node evolves via a local map (default: doubling map x ↦ 2x mod 1),\n",
    "    plus diffusive sinusoidal coupling from its in-neighbors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.ndarray\n",
    "        Directed adjacency matrix of shape (N, N). A[j, i] = 1 indicates j → i.\n",
    "    alpha : str, optional\n",
    "        Coupling strength as a decimal string (for exact Decimal parsing).\n",
    "    local_map : Callable[[Decimal], Decimal], optional\n",
    "        Local map f(x). Defaults to doubling map `(2*x) % 1`.\n",
    "    coupling_fn : Callable[[Decimal, Decimal], Decimal], optional\n",
    "        Pairwise coupling c(x_s, x_t) from source s to target t. If None,\n",
    "        uses a sinusoidal diffusive term `-sin(2π x_s) + sin(2π x_t)`.\n",
    "    seed : int, optional\n",
    "        Random seed for initial conditions.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes.\n",
    "    Delta : float\n",
    "        Maximum out-degree (max column sum) used for normalization.\n",
    "    x : list[Decimal]\n",
    "        Current node states.\n",
    "    t : int\n",
    "        Current time step.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - High precision is enforced via Python's Decimal and mpmath.\n",
    "    - The coupling increment at node i is normalized by Delta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A: np.ndarray, alpha: str = '0.25',\n",
    "                 local_map: Callable[[Decimal], Decimal] | None = None,\n",
    "                 coupling_fn: Callable[[Decimal, Decimal], Decimal] | None = None,\n",
    "                 seed: int = 0):\n",
    "        self.A = np.asarray(A, dtype=float)\n",
    "        self.N = self.A.shape[0]\n",
    "        self.Delta = self.A.sum(axis=0).max()\n",
    "        self.alpha = Decimal(alpha)\n",
    "        self.local_map = local_map or (lambda x: (Decimal(2) * x) % 1)\n",
    "        self.coupling = coupling_fn or self._default_coupling\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.reset()\n",
    "\n",
    "    @staticmethod\n",
    "    def _default_coupling(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "        \"\"\"\n",
    "        Default sinusoidal diffusive coupling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xs : Decimal\n",
    "            Source node state.\n",
    "        xt : Decimal\n",
    "            Target node state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Decimal\n",
    "            c(xs, xt) = -sin(2π xs) + sin(2π xt), as a Decimal.\n",
    "        \"\"\"\n",
    "        v = -mp.sin(TWOPI * mp.mpf(str(xs))) + mp.sin(TWOPI * mp.mpf(str(xt)))\n",
    "        return Decimal(str(v))\n",
    "\n",
    "    def _coupling_term(self):\n",
    "        \"\"\"\n",
    "        Compute normalized coupling increment for each node.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Decimal]\n",
    "            A list of length N with the coupling increment for each node,\n",
    "            normalized by the maximum out-degree Δ.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The increment for node i is the sum over j with A[j, i] = 1 of\n",
    "        c(x_j, x_i), divided by Δ to keep scales comparable across graphs.\n",
    "        \"\"\"\n",
    "        incr = [Decimal(0)] * self.N\n",
    "        for j in range(self.N):\n",
    "            if self.A[j].sum() == 0:\n",
    "                continue  # node j has no outgoing edges\n",
    "            for i in range(self.N):\n",
    "                if self.A[j, i]:\n",
    "                    incr[i] += self.coupling(self.x[j], self.x[i])\n",
    "        d = Decimal(str(self.Delta))\n",
    "        return [v / d for v in incr]\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Advance the system by one time step.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Decimal]\n",
    "            The updated state vector x_{t+1} (length N) as Decimals.\n",
    "        \"\"\"\n",
    "        xn = [self.local_map(x) for x in self.x]  # local map update\n",
    "        coup = self._coupling_term()              # diffusive coupling\n",
    "        xn = [(xi + self.alpha * ci) % 1 for xi, ci in zip(xn, coup)]\n",
    "        self.x = xn\n",
    "        self.t += 1\n",
    "        return xn\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the system to a fresh random initial condition.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        States are sampled i.i.d. ~ Uniform(0, 1) and stored as Decimal.\n",
    "        \"\"\"\n",
    "        self.x = [Decimal(str(v)) for v in self.rng.random(self.N)]\n",
    "        self.t = 0\n",
    "\n",
    "    def run(self, T: int, discard: int = 0):\n",
    "        \"\"\"\n",
    "        Simulate for T time steps and return the trajectory after discarding transients.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        T : int\n",
    "            Total number of steps to simulate.\n",
    "        discard : int, optional\n",
    "            Number of initial steps to discard as transients.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of shape (N, max(0, T - discard)) with float64 views of states.\n",
    "        \"\"\"\n",
    "        traj = np.zeros((self.N, max(0, T - discard)))\n",
    "        for k in range(T):\n",
    "            xt = self.step()\n",
    "            if k >= discard:\n",
    "                traj[:, k - discard] = [float(v) for v in xt]\n",
    "        return traj\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  II. Star Graph Generators (three variants)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def graph_A(N: int):\n",
    "    \"\"\"\n",
    "    Create a star graph with a single hub (node N-1) pointed to by all leaves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Adjacency matrix A of shape (N, N) with A[j, N-1] = 1 for j = 0..N-2.\n",
    "    \"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    A[np.arange(N - 1), N - 1] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_B(N: int):\n",
    "    \"\"\"\n",
    "    Create a star-like graph with two hubs (nodes N-2 and N-1).\n",
    "    Every leaf connects to both hubs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Adjacency matrix A with A[leaf, N-1] = A[leaf, N-2] = 1 for all leaves.\n",
    "    \"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    leaves = np.arange(N - 2)\n",
    "    A[leaves, N - 1] = 1\n",
    "    A[leaves, N - 2] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_C(N: int):\n",
    "    \"\"\"\n",
    "    Create a two-hub graph where leaves are split into two halves;\n",
    "    each half connects to exactly one of the hubs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Adjacency matrix A with two hubs (N-2, N-1) and disjoint leaf sets.\n",
    "    \"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    half = N // 2\n",
    "    A[np.arange(half - 1), N - 2] = 1\n",
    "    A[np.arange(half - 1, N - 2), N - 1] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  III. GMM-based Hub Detection & Core Statistics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def moddiff(u):\n",
    "    \"\"\"\n",
    "    Wrap a real array onto the interval (-0.5, 0.5] using modulo-1 arithmetic.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : array_like\n",
    "        Input values (can be scalar or array).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray or float\n",
    "        Wrapped values with the same shape as input.\n",
    "    \"\"\"\n",
    "    return ((u + 0.5) % 1) - 0.5\n",
    "\n",
    "\n",
    "def compute_strength(traj):\n",
    "    \"\"\"\n",
    "    Compute node-wise mean error strength ‖x_{t+1} - 2 x_t‖ (wrapped).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory of shape (N, T), after discarding transients.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Vector of length N, where entry i is the mean absolute wrapped error\n",
    "        for node i across time.\n",
    "    \"\"\"\n",
    "    x, x1 = traj[:, :-1], traj[:, 1:]\n",
    "    return np.abs(moddiff(x1 - 2 * x)).mean(axis=1)\n",
    "\n",
    "\n",
    "def gmm_hubs(S, seed=0):\n",
    "    \"\"\"\n",
    "    Use a 2-component Gaussian Mixture Model to separate hubs (larger error\n",
    "    strength) from leaves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S : np.ndarray\n",
    "        Mean error strengths for N nodes; shape (N,).\n",
    "    seed : int, optional\n",
    "        Random seed for GMM initialization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Boolean mask of shape (N,), where True indicates a hub (the component\n",
    "        with the larger mean).\n",
    "    \"\"\"\n",
    "    g = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    return g.predict(S.reshape(-1, 1)) == np.argmax(g.means_)\n",
    "\n",
    "\n",
    "def beta_var(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Estimate the variance of residuals in\n",
    "    y_t = x_{t+1} - 2 x_t + β sin(2π x_t), via least squares for β.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Single-node time series of shape (T,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Variance of residuals y_t + β sin(2π x_t).\n",
    "    \"\"\"\n",
    "    y = moddiff(x[1:] - 2 * x[:-1])\n",
    "    s = -np.sin(2 * np.pi * x[:-1])\n",
    "    beta = -(y @ s) / (s @ s)\n",
    "    resid = y + beta * s\n",
    "    return resid.var()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  IV-a  Single Segment → Classify A vs (B/C)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def classify_A_and_BC(traj: np.ndarray, N: int) -> str:\n",
    "    \"\"\"\n",
    "    Classify a single segment as 'A_N' (exactly one hub) or 'B_N and C_N' (two hubs).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T).\n",
    "    N : int\n",
    "        Number of nodes (kept for signature compatibility; not used).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        'A_N' if exactly one hub is detected; otherwise 'B_N and C_N'.\n",
    "    \"\"\"\n",
    "    S = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    if hubs.size == 1:\n",
    "        return \"A_N\"\n",
    "    return \"B_N and C_N\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  IV-b  Compute \"mean hub variance\" for one segment\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def average_hub_variance(traj: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mean β-residual variance over the two hubs of a B/C star graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average of beta_var over the two hubs.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the segment does not appear to have exactly two hubs.\n",
    "    \"\"\"\n",
    "    S = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    if hubs.size != 2:\n",
    "        raise RuntimeError(\"This segment does not correspond to a B/C graph (number of hubs ≠ 2)\")\n",
    "    return float(np.mean([beta_var(traj[i]) for i in hubs]))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  IV-c **Key addition**: Two segments → compare variances → classify B vs C\n",
    "# ------------------------------------------------------------------\n",
    "def classify_B_vs_C(traj_first: np.ndarray, traj_second: np.ndarray) -> Tuple[str, float, float]:\n",
    "    \"\"\"\n",
    "    Distinguish type-B vs. type-C using hub residual variances from two segments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj_first : np.ndarray\n",
    "        First trajectory, shape (N, T), from a B/C candidate graph.\n",
    "    traj_second : np.ndarray\n",
    "        Second trajectory, shape (N, T), from a B/C candidate graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, float, float]\n",
    "        (label, var_first, var_second)\n",
    "        - label: 'first_is_B' if var_first < var_second, else 'first_is_C'\n",
    "        - var_first: mean hub variance of the first segment\n",
    "        - var_second: mean hub variance of the second segment\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Lower hub variance ⇒ higher in-degree ⇒ type-B.\n",
    "    \"\"\"\n",
    "    var1 = average_hub_variance(traj_first)\n",
    "    var2 = average_hub_variance(traj_second)\n",
    "    if var1 < var2:  # smaller variance ⇒ larger in-degree ⇒ B graph\n",
    "        return \"first_is_B\", var1, var2\n",
    "    else:\n",
    "        return \"first_is_C\", var1, var2\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  V. Demo\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    N, T, discard = 10, 6000, 600\n",
    "    alpha = '0.25'\n",
    "\n",
    "    # 1) Demonstrate single-segment classification A/B/C\n",
    "    for gname, maker in [(\"A_N\", graph_A), (\"B_N\", graph_B), (\"C_N\", graph_C)]:\n",
    "        traj = GraphSystemDecimal(maker(N), alpha=alpha, seed=hash(gname) % 2**32).run(T, discard)\n",
    "        print(f\"{gname}  → classify_ABC → {classify_A_and_BC(traj, N)}\")\n",
    "\n",
    "    # 2) Demonstrate variance comparison to distinguish B / C\n",
    "    trajB = GraphSystemDecimal(graph_B(N), alpha=alpha, seed=1).run(T, discard)\n",
    "    trajC = GraphSystemDecimal(graph_C(N), alpha=alpha, seed=2).run(T, discard)\n",
    "\n",
    "    res, v_first, v_second = classify_B_vs_C(trajB, trajC)  # B comes first\n",
    "    print(\"\\nComparing two sequences:\", res)\n",
    "    print(f\"  Mean hub variance of the first segment  = {v_first:.6e}\")\n",
    "    print(f\"  Mean hub variance of the second segment = {v_second:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2915cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96235c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_N  → classify_ABC → A_N\n",
      "B_N  → classify_ABC → B_N and C_N\n",
      "C_N  → classify_ABC → B_N and C_N\n",
      "\n",
      "Compare the two sequences: first_is_B\n",
      "  Mean hub variance for the first sequence  = 2.936251e-03\n",
      "  Mean hub variance for the second sequence = 6.113247e-03\n"
     ]
    }
   ],
   "source": [
    "# ======== New or Replacement Section Begins =================================\n",
    "# I. General Logistic Map (Decimal version, co-existing with original 2 x mod 1)\n",
    "def logistic_map_decimal(x: Decimal) -> Decimal:\n",
    "    \"\"\"\n",
    "    Logistic map in Decimal precision: f(x) = 4 x (1 - x)  (mod 1).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Decimal\n",
    "        State value in [0, 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Decimal\n",
    "        f(x) mapped back to [0, 1) using modulo-1, to match the original design.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Keeping the modulo-1 ensures consistency with the doubling-map implementation.\n",
    "    \"\"\"\n",
    "    # “% 1” keeps the same format as in the original implementation\n",
    "    return (Decimal(4) * x * (Decimal(1) - x)) % 1\n",
    "\n",
    "\n",
    "# II. Example interface for an optional coupling function\n",
    "def coupling_sin_diff(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "    \"\"\"\n",
    "    Sinusoidal diffusive coupling in Decimal precision:\n",
    "    c(xs, xt) = -sin(2π xs) + sin(2π xt).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xs : Decimal\n",
    "        Source node state.\n",
    "    xt : Decimal\n",
    "        Target node state.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Decimal\n",
    "        Coupling contribution from xs to xt.\n",
    "    \"\"\"\n",
    "    v = -mp.sin(TWOPI * mp.mpf(str(xs))) + mp.sin(TWOPI * mp.mpf(str(xt)))\n",
    "    return Decimal(str(v))\n",
    "\n",
    "\n",
    "# III. --- Modify compute_strength / beta_var so they depend on local_map ---\n",
    "def compute_strength(\n",
    "    traj: np.ndarray,\n",
    "    local_map_vec: Callable[[np.ndarray], np.ndarray]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute node-wise mean absolute innovation relative to the local map:\n",
    "    S_i = ⟨|Δ_i|⟩, where Δ_i(t) = x_{t+1,i} − f(x_{t,i}) wrapped by modulo-1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T) for N nodes and T time steps\n",
    "        (after any transient discard).\n",
    "    local_map_vec : Callable[[np.ndarray], np.ndarray]\n",
    "        Vectorized local map f applied elementwise to traj[:, :-1].\n",
    "        It must accept an array of shape (N, T-1) and return the same shape.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Strength vector S of shape (N,), one entry per node.\n",
    "    \"\"\"\n",
    "    x, x1 = traj[:, :-1], traj[:, 1:]\n",
    "    Delta = moddiff(x1 - local_map_vec(x))\n",
    "    return np.abs(Delta).mean(axis=1)\n",
    "\n",
    "\n",
    "def beta_var(\n",
    "    traj_i: np.ndarray,\n",
    "    local_map_vec: Callable[[np.ndarray], np.ndarray],\n",
    "    I_h_vec: Callable[[np.ndarray], np.ndarray]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimate β by least squares and return the residual variance for one node.\n",
    "\n",
    "    Model\n",
    "    -----\n",
    "    y_t = x_{t+1} − f(x_t) + β · I_h(x_t),\n",
    "    where I_h(x) = ∫ h(x, y) dm(y).\n",
    "    All differences are wrapped via modulo-1 to stay on the circle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj_i : np.ndarray\n",
    "        Single-node series of shape (T,).\n",
    "    local_map_vec : Callable[[np.ndarray], np.ndarray]\n",
    "        Vectorized local map f for arrays of shape (T-1,) → (T-1,).\n",
    "    I_h_vec : Callable[[np.ndarray], np.ndarray]\n",
    "        Vectorized function I_h for arrays of shape (T-1,) → (T-1,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Variance of residuals y + β · I_h(x).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    β is obtained by minimizing ‖y + β s‖² with s = I_h(x), yielding\n",
    "    β* = −(yᵀ s)/(sᵀ s).\n",
    "    \"\"\"\n",
    "    x     = traj_i[:-1]\n",
    "    y     = moddiff(traj_i[1:] - local_map_vec(x))\n",
    "    s     = I_h_vec(x)\n",
    "    beta  = -(y @ s) / (s @ s)\n",
    "    resid = y + beta * s\n",
    "    return resid.var()\n",
    "\n",
    "\n",
    "# IV. --- Vectorized utilities, isolated from the Decimal system -------------\n",
    "# logistic_vec: elementwise version of f(x) = 4x(1-x) acting on ndarray inputs.\n",
    "logistic_vec = np.vectorize(lambda u: 4.0 * u * (1.0 - u))          # f(x)\n",
    "\n",
    "# Ih_vec: elementwise version of I_h(x) = ∫ h(x, y) dm(y); here chosen as -sin(2πx).\n",
    "Ih_vec       = np.vectorize(lambda u: -np.sin(2 * np.pi * u))       # ∫ h dm\n",
    "\n",
    "\n",
    "# V. --- Adapted classification functions -----------------------------------\n",
    "def classify_A_and_BC(traj: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Classify a single segment as 'A_N' (one hub) or 'B_N and C_N' (two hubs),\n",
    "    using the logistic local map and sinusoidal integral I_h by default.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        'A_N' if exactly one hub is detected by GMM; otherwise 'B_N and C_N'.\n",
    "    \"\"\"\n",
    "    S    = compute_strength(traj, logistic_vec)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    return \"A_N\" if hubs.size == 1 else \"B_N and C_N\"\n",
    "\n",
    "\n",
    "def average_hub_variance(traj: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mean residual variance across the two detected hubs\n",
    "    for a B/C star graph, using the logistic local map and I_h.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Average of beta_var over the two hubs.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the number of detected hubs is not exactly two.\n",
    "    \"\"\"\n",
    "    S    = compute_strength(traj, logistic_vec)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    if hubs.size != 2:\n",
    "        raise RuntimeError(\"Data are not from a B/C graph (number of hubs ≠ 2)\")\n",
    "    vars_ = [beta_var(traj[i], logistic_vec, Ih_vec) for i in hubs]\n",
    "    return float(np.mean(vars_))\n",
    "\n",
    "\n",
    "# VI. ------------------------ Demo -----------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Demo: run the system under the logistic map and sinusoidal coupling,\n",
    "    then classify A/B/C for single segments and distinguish B vs C by variance.\n",
    "    \"\"\"\n",
    "    N, T, discard = 10, 6000, 600\n",
    "    alpha = '0.25'\n",
    "\n",
    "    local_map = logistic_map_decimal\n",
    "    coupling  = coupling_sin_diff\n",
    "\n",
    "    # Demonstrate single-segment classification for A/B/C\n",
    "    for gname, maker in [(\"A_N\", graph_A),\n",
    "                         (\"B_N\", graph_B),\n",
    "                         (\"C_N\", graph_C)]:\n",
    "        gs   = GraphSystemDecimal(maker(N), alpha=alpha,\n",
    "                                  local_map=local_map,\n",
    "                                  coupling_fn=coupling,\n",
    "                                  seed=hash(gname) % 2**32)\n",
    "        traj = gs.run(T, discard)\n",
    "        print(f\"{gname}  → classify_ABC → {classify_A_and_BC(traj)}\")\n",
    "\n",
    "    # Compare two sequences to distinguish between B and C\n",
    "    trajB = GraphSystemDecimal(graph_B(N), alpha=alpha,\n",
    "                               local_map=local_map,\n",
    "                               coupling_fn=coupling,\n",
    "                               seed=1).run(T, discard)\n",
    "    trajC = GraphSystemDecimal(graph_C(N), alpha=alpha,\n",
    "                               local_map=local_map,\n",
    "                               coupling_fn=coupling,\n",
    "                               seed=2).run(T, discard)\n",
    "\n",
    "    res, v_first, v_second = classify_B_vs_C(trajB, trajC)\n",
    "    print(\"\\nCompare the two sequences:\", res)\n",
    "    print(f\"  Mean hub variance for the first sequence  = {v_first:.6e}\")\n",
    "    print(f\"  Mean hub variance for the second sequence = {v_second:.6e}\")\n",
    "# ======== New or Replacement Section Ends ===================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607c32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory B → classified as: B_N | debug: {'V_hat': 0.0005113619541740942, 'V_B_th': 0.0005076322209635416, 'V_C_th': 0.0010152644419270831, 'd_B': 0.0073204537525510815, 'd_C': 0.6858267268073943, 'hubs': [48, 49]}\n",
      "Trajectory C → classified as: C_N | debug: {'V_hat': 0.0010205339499985673, 'V_B_th': 0.0005076322209635416, 'V_C_th': 0.0010152644419270831, 'd_B': 0.6983240387998242, 'd_C': 0.00517685823987879, 'hubs': [48, 49]}\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1. Theoretical variance function ---------------------\n",
    "def theoretical_hub_variance(N: int,\n",
    "                             graph_type: str,\n",
    "                             sigma_h2: float = 0.3898615457,\n",
    "                             alpha: float = 0.25) -> float:\n",
    "    \"\"\"\n",
    "    Compute the closed-form (idealized) variance of hub nodes for type-B or type-C stars.\n",
    "\n",
    "    The model assumes a diffusive coupling with per-step innovation variance\n",
    "    proportional to σ_h^2 and a normalization by the maximum out-degree Δ.\n",
    "    For star variants:\n",
    "      - B: every leaf connects to both hubs → L = N - 2, Δ = N - 2\n",
    "      - C: leaves split evenly across the two hubs → L = N//2 - 1, Δ = N//2 - 1\n",
    "\n",
    "    The returned variance is:\n",
    "        Var_hub = (alpha**2) * sigma_h2 * L / (Delta**2)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes in the graph.\n",
    "    graph_type : str\n",
    "        'B' or 'C' for the corresponding star topology.\n",
    "    sigma_h2 : float, optional\n",
    "        The integral of squared kernel (e.g., σ_h^2 = ∫ h^2 dm) used by the theory.\n",
    "    alpha : float, optional\n",
    "        Coupling strength.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Theoretical hub variance for the specified graph type.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `graph_type` is not 'B' or 'C'.\n",
    "    \"\"\"\n",
    "    if graph_type == \"B\":\n",
    "        L = N - 2\n",
    "        Delta = N - 2\n",
    "    elif graph_type == \"C\":\n",
    "        L = N // 2 - 1\n",
    "        Delta = N // 2 - 1\n",
    "    else:\n",
    "        raise ValueError(\"graph_type must be 'B' or 'C'\")\n",
    "    return (alpha ** 2) * sigma_h2 * L / (Delta ** 2)\n",
    "\n",
    "\n",
    "# ---------- 2. Single-sequence B/C classification -------------------\n",
    "def classify_single_BC_theory(traj: np.ndarray, N: int) -> tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Classify a single N×T trajectory as 'B_N' or 'C_N' by matching empirical vs. theoretical hub variances.\n",
    "\n",
    "    Procedure\n",
    "    ---------\n",
    "    a) Detect hubs with a 2-component GMM on node strength S_i = ⟨|Δ_i|⟩ where\n",
    "       Δ_i(t) = x_{t+1,i} − f(x_{t,i}), using the logistic local map f.\n",
    "    b) Compute empirical hub variance V_hat as the mean of β-residual variances\n",
    "       across the two hubs (see `average_hub_variance`).\n",
    "    c) Compute theoretical hub variances V_B_th, V_C_th via `theoretical_hub_variance`.\n",
    "    d) Pick the label minimizing |log V_hat − log V_th|.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray\n",
    "        Trajectory array of shape (N, T), after any transient discard.\n",
    "    N : int\n",
    "        Number of nodes (used in the theoretical formulas).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, dict]\n",
    "        - label : {'B_N', 'C_N'}\n",
    "            Predicted graph type for the given trajectory.\n",
    "        - info : dict\n",
    "            Debugging payload with keys:\n",
    "              * 'V_hat'  : float, empirical mean hub variance\n",
    "              * 'V_B_th' : float, theoretical hub variance for type-B\n",
    "              * 'V_C_th' : float, theoretical hub variance for type-C\n",
    "              * 'd_B'    : float, |log(V_hat) - log(V_B_th)|\n",
    "              * 'd_C'    : float, |log(V_hat) - log(V_C_th)|\n",
    "              * 'hubs'   : list[int], indices of detected hubs\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the detected number of hubs is not exactly two.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function relies on the global `logistic_vec`, `gmm_hubs`, and\n",
    "      `average_hub_variance` utilities defined elsewhere.\n",
    "    - Assumes V_hat, V_B_th, V_C_th > 0 so that logarithms are defined.\n",
    "    \"\"\"\n",
    "    # a) Locate hubs\n",
    "    S = compute_strength(traj, logistic_vec)          # Use a different mapper? Modify this call.\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    if hubs.size != 2:\n",
    "        raise RuntimeError(\"Number of hubs in trajectory ≠ 2; not a B/C graph\")\n",
    "\n",
    "    # b) Empirical average variance of hubs\n",
    "    V_hat = average_hub_variance(traj)\n",
    "\n",
    "    # c) Theoretical values\n",
    "    V_B_th = theoretical_hub_variance(N, \"B\")\n",
    "    V_C_th = theoretical_hub_variance(N, \"C\")\n",
    "\n",
    "    # d) Log-distance between empirical and theoretical variances\n",
    "    d_B = abs(np.log(V_hat) - np.log(V_B_th))\n",
    "    d_C = abs(np.log(V_hat) - np.log(V_C_th))\n",
    "\n",
    "    label = \"B_N\" if d_B < d_C else \"C_N\"\n",
    "    info = {\n",
    "        \"V_hat\": V_hat,\n",
    "        \"V_B_th\": V_B_th,\n",
    "        \"V_C_th\": V_C_th,\n",
    "        \"d_B\": d_B,\n",
    "        \"d_C\": d_C,\n",
    "        \"hubs\": hubs.tolist(),\n",
    "    }\n",
    "    return label, info\n",
    "\n",
    "\n",
    "# ---------- 3. Demo --------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Demo\n",
    "    ----\n",
    "    Generate trajectories from type-B and type-C stars under the logistic map\n",
    "    and sinusoidal diffusive coupling, then classify each single sequence using\n",
    "    the theory-matching approach above.\n",
    "    \"\"\"\n",
    "    N, T, discard = 50, 8000, 800\n",
    "    alpha = 0.25\n",
    "    local_map = logistic_map_decimal\n",
    "    coupling  = coupling_sin_diff\n",
    "\n",
    "    # Simulate B and C star graphs\n",
    "    trajB = (GraphSystemDecimal(graph_B(N),\n",
    "                                alpha=alpha,\n",
    "                                local_map=local_map,\n",
    "                                coupling_fn=coupling,\n",
    "                                seed=1)\n",
    "             .run(T, discard))\n",
    "    trajC = (GraphSystemDecimal(graph_C(N),\n",
    "                                alpha=alpha,\n",
    "                                local_map=local_map,\n",
    "                                coupling_fn=coupling,\n",
    "                                seed=2)\n",
    "             .run(T, discard))\n",
    "\n",
    "    # Classify each trajectory independently\n",
    "    resB, infoB = classify_single_BC_theory(trajB, N)\n",
    "    resC, infoC = classify_single_BC_theory(trajC, N)\n",
    "\n",
    "    print(\"Trajectory B → classified as:\", resB, \"| debug:\", infoB)\n",
    "    print(\"Trajectory C → classified as:\", resC, \"| debug:\", infoC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45356cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff062ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alghrithm 2.1 H(x,y) is just Lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f19540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_N  → classify_ABC → A_N\n",
      "B_N  → classify_ABC → B_N and C_N\n",
      "C_N  → classify_ABC → B_N and C_N\n",
      "\n",
      "B/C decision: first_is_B\n",
      "D_BC=3.141e-01 (seg1=B, seg2=C) | D_CB=1.072e+00 (seg1=C, seg2=B)\n",
      "alpha^2 under (B,C) = (0.08562910549884833, 0.06254701302597973)\n",
      "alpha^2 under (C,B) = (0.04281455274942417, 0.12509402605195946)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "B/C star-network classifier via alpha^2-consistency and hub empirical law.\n",
    "\n",
    "This module provides:\n",
    "  1) A high-precision coupled-map simulator on a directed graph with states on\n",
    "     the one-dimensional torus T = R/Z (represented by [0, 1)).\n",
    "  2) Star-graph generators for types A, B, and C.\n",
    "  3) Utilities to detect hubs from data (2-component GMM on per-node errors).\n",
    "  4) Segment-level statistics for hubs:\n",
    "       - residual variance V (from a least-squares regression y ~ m_h(x)),\n",
    "       - empirical expectation K_hat = <K(x_t)> using the hub time series,\n",
    "     where m_h(x) = ∫ h(x,y) dm(y) and K(x) = Var_y[h(x,y)] are known in closed form.\n",
    "  5) A parameter-free B-vs-C classifier that uses two time segments with a\n",
    "     common (unknown) coupling strength α and decides which segment is B and\n",
    "     which is C by comparing the consistency of the implied α^2 under the\n",
    "     two topological hypotheses.\n",
    "\n",
    "Default model (matches the math write-up):\n",
    "  - Local map: f(x) = 2 x (mod 1).\n",
    "  - Coupling  : h(x, y) = 2 sin(x) sin(y).  (x, y are angles in radians.)\n",
    "  - Invariant measure for leaves: Lebesgue on the circle.\n",
    "  - Normalization: the coupling term at node i is divided by Δ = max in-degree.\n",
    "\n",
    "Dependencies:\n",
    "  numpy, mpmath, scikit-learn (GaussianMixture).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Callable, Tuple, Dict, Any\n",
    "\n",
    "import mpmath as mp\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Global precision for Decimal and mpmath (used in the simulator)\n",
    "# ---------------------------------------------------------------------\n",
    "getcontext().prec = 200     # Decimal precision\n",
    "mp.mp.dps = getcontext().prec\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# High-precision network simulator\n",
    "# ---------------------------------------------------------------------\n",
    "class GraphSystemDecimal:\n",
    "    \"\"\"\n",
    "    Coupled-map lattice on a directed graph with high-precision arithmetic.\n",
    "\n",
    "    State space: one-dimensional torus T = R/Z (represented by [0, 1)).\n",
    "    Update rule for node n (mod 1):\n",
    "        x_n(t+1) = f(x_n(t)) + (alpha / Delta) * sum_{j: A[j, n]=1} h(x_n(t), x_j(t)),\n",
    "    where Delta = max in-degree over all nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.ndarray (N x N)\n",
    "        Directed adjacency matrix. A[j, i] = 1 means edge j -> i (j contributes to i).\n",
    "    alpha : str\n",
    "        Coupling strength as a string, parsed into Decimal for precision.\n",
    "    local_map : Callable[[Decimal], Decimal], optional\n",
    "        Local map f acting on Decimal in [0,1). Default: doubling map (2*x) % 1.\n",
    "    coupling_fn : Callable[[Decimal, Decimal], Decimal], optional\n",
    "        Pairwise coupling h(xs, xt) from source xs to target xt. Default: 2 sin xs sin xt.\n",
    "    seed : int\n",
    "        RNG seed for i.i.d. Uniform(0,1) initialization of the states.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of nodes.\n",
    "    Delta : float\n",
    "        Maximum in-degree (max column sum of A), used for normalization.\n",
    "    x : list[Decimal]\n",
    "        Current state vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        A: np.ndarray,\n",
    "        alpha: str = \"0.25\",\n",
    "        local_map: Callable[[Decimal], Decimal] | None = None,\n",
    "        coupling_fn: Callable[[Decimal, Decimal], Decimal] | None = None,\n",
    "        seed: int = 0,\n",
    "    ):\n",
    "        self.A = np.asarray(A, dtype=float)\n",
    "        self.N = self.A.shape[0]\n",
    "        # Max in-degree (column sum) for normalization\n",
    "        self.Delta = self.A.sum(axis=0).max()\n",
    "        self.alpha = Decimal(alpha)\n",
    "        # Default local map: doubling map on the circle\n",
    "        self.local_map = local_map or (lambda z: (Decimal(2) * z) % 1)\n",
    "        # Default coupling: h(xs, xt) = 2 sin xs sin xt\n",
    "        self.coupling = coupling_fn or coupling_sin_sin\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def _coupling_term(self) -> list[Decimal]:\n",
    "        \"\"\"\n",
    "        Compute the normalized coupling increment for each node.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Decimal]\n",
    "            For each node i, the quantity (1/Delta) * sum_{j} A[j, i] * h(x_j, x_i).\n",
    "        \"\"\"\n",
    "        incr = [Decimal(0)] * self.N\n",
    "        for j in range(self.N):\n",
    "            if self.A[j].sum() == 0:\n",
    "                continue  # node j has no outgoing edges\n",
    "            for i in range(self.N):\n",
    "                if self.A[j, i]:\n",
    "                    incr[i] += self.coupling(self.x[j], self.x[i])\n",
    "        d = Decimal(str(self.Delta))\n",
    "        return [v / d for v in incr]\n",
    "\n",
    "    def step(self) -> list[Decimal]:\n",
    "        \"\"\"\n",
    "        Advance the system by one step: x <- f(x) + alpha * coupling (mod 1).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Decimal]\n",
    "            The updated state vector.\n",
    "        \"\"\"\n",
    "        xn = [self.local_map(x) for x in self.x]  # apply f\n",
    "        coup = self._coupling_term()\n",
    "        xn = [(xi + self.alpha * ci) % 1 for xi, ci in zip(xn, coup)]\n",
    "        self.x = xn\n",
    "        return xn\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset states to i.i.d. Uniform(0,1) in Decimal precision.\"\"\"\n",
    "        self.x = [Decimal(str(v)) for v in self.rng.random(self.N)]\n",
    "\n",
    "    def run(self, T: int, discard: int = 0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simulate for T steps and return the trajectory after discarding a transient.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        T : int\n",
    "            Total number of simulation steps.\n",
    "        discard : int\n",
    "            Number of initial steps to discard as transient.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of shape (N, max(0, T - discard)) with float64 snapshots of states.\n",
    "        \"\"\"\n",
    "        traj = np.zeros((self.N, max(0, T - discard)))\n",
    "        for k in range(T):\n",
    "            xt = self.step()\n",
    "            if k >= discard:\n",
    "                traj[:, k - discard] = [float(v) for v in xt]\n",
    "        return traj\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Star graph generators (A: single hub; B: two hubs, all leaves to both;\n",
    "# C: two hubs, leaves split into two disjoint halves)\n",
    "# ---------------------------------------------------------------------\n",
    "def graph_A(N: int) -> np.ndarray:\n",
    "    \"\"\"Star with one hub at index N-1 (all leaves point to the hub).\"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    A[np.arange(N - 1), N - 1] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_B(N: int) -> np.ndarray:\n",
    "    \"\"\"Two hubs at indices N-2 and N-1; every leaf connects to both hubs.\"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    leaves = np.arange(N - 2)\n",
    "    A[leaves, N - 1] = 1\n",
    "    A[leaves, N - 2] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_C(N: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Two hubs at indices N-2 and N-1; the leaves (0..N-3) are split evenly:\n",
    "    first half -> hub N-2, second half -> hub N-1.\n",
    "    \"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    L = N - 2       # number of leaves\n",
    "    half = L // 2\n",
    "    first = np.arange(0, half)\n",
    "    second = np.arange(half, L)\n",
    "    A[first, N - 2] = 1\n",
    "    A[second, N - 1] = 1\n",
    "    return A\n",
    "\n",
    "def graph_A_like(N: int) -> np.ndarray:\n",
    "    \"\"\"Star with one hub at index N-1 (all leaves point to the hub).\"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    A[np.arange(N - 1), N - 1] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_B_like(N: int) -> np.ndarray:\n",
    "    \"\"\"Two hubs at indices N-2 and N-1; every leaf connects to both hubs.\"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    leaves = np.arange(N - 2)\n",
    "    A[leaves, N - 1] = 1\n",
    "    A[leaves, N - 2] = 1\n",
    "    A_leaves=np.arange(0,int(N/3)-2)\n",
    "    B_leaves=np.arange(int(N*2/3),N-2)\n",
    "    A[A_leaves,N-1]=0\n",
    "    A[B_leaves,N-2]=0\n",
    "    return A\n",
    "\n",
    "\n",
    "def graph_C_like(N: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Two hubs at indices N-2 and N-1; the leaves (0..N-3) are split evenly:\n",
    "    first half -> hub N-2, second half -> hub N-1.\n",
    "    \"\"\"\n",
    "    A = np.zeros((N, N))\n",
    "    L = N - 2       # number of leaves\n",
    "    half = L // 2\n",
    "    first = np.arange(0, half)\n",
    "    second = np.arange(half, L)\n",
    "    A[first, N - 2] = 1\n",
    "    A[second, N - 1] = 1\n",
    "    return A\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Model-specific h, its integral m_h, and the variance kernel K\n",
    "#   h(x, y) = 2 sin x sin y   (angles in radians)\n",
    "#   m_h(x)  = ∫ h(x, y) dm(y) = C1 sin x\n",
    "#   K(x)    = Var_y[h(x, y)]  = CK sin^2 x\n",
    "# ---------------------------------------------------------------------\n",
    "def coupling_sin_sin(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "    \"\"\"High-precision coupling: h(xs, xt) = 2 sin(xs) sin(xt).\"\"\"\n",
    "    v = 2.0 * float(mp.sin(mp.mpf(str(xs)))) * float(mp.sin(mp.mpf(str(xt))))\n",
    "    return Decimal(str(v))\n",
    "\n",
    "\n",
    "C1 = 2.0 * (1.0 - np.cos(1.0))                       # coefficient in m_h(x)\n",
    "CK = (2.0 - np.sin(2.0)) - C1**2                     # coefficient in K(x)\n",
    "\n",
    "\n",
    "def doubling_vec(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Vectorized local map f(x) = 2x (mod 1) acting elementwise.\"\"\"\n",
    "    return (2.0 * u) % 1.0\n",
    "\n",
    "\n",
    "def Ih_vec(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Vectorized m_h(x) = C1 * sin(x).\"\"\"\n",
    "    return C1 * np.sin(u)\n",
    "\n",
    "\n",
    "def K_vec(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Vectorized K(x) = CK * sin(x)^2.\"\"\"\n",
    "    return CK * np.sin(u) ** 2\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utilities: modular difference, node-wise strength, and hub detection\n",
    "# ---------------------------------------------------------------------\n",
    "def moddiff(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Wrap values into (-0.5, 0.5] by subtracting the nearest integer.\n",
    "    Useful for measuring errors on the circle.\n",
    "    \"\"\"\n",
    "    return ((u + 0.5) % 1.0) - 0.5\n",
    "\n",
    "\n",
    "def compute_strength(traj: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Per-node mean absolute innovation relative to the local map:\n",
    "      S_i = < |x_{t+1,i} - f(x_{t,i})|_{mod 1} >_t.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray (N x T)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray (N,)\n",
    "        Mean wrapped absolute error for each node.\n",
    "    \"\"\"\n",
    "    x, x1 = traj[:, :-1], traj[:, 1:]\n",
    "    Delta = moddiff(x1 - doubling_vec(x))\n",
    "    return np.abs(Delta).mean(axis=1)\n",
    "\n",
    "\n",
    "def gmm_hubs(S: np.ndarray, seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Identify hubs by a 2-component Gaussian Mixture Model (GMM) fitted to S.\n",
    "    The component with the larger mean is labeled as hubs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S : np.ndarray (N,)\n",
    "        Node-wise strengths.\n",
    "    seed : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray (N,) of bool\n",
    "        True for nodes classified as hubs.\n",
    "    \"\"\"\n",
    "    g = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    return g.predict(S.reshape(-1, 1)) == np.argmax(g.means_)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Residual variance at a single hub:\n",
    "#   y_t = x_{t+1} - f(x_t)   (wrapped)\n",
    "#   s_t = m_h(x_t)\n",
    "#   beta = argmin_b || y + b * s ||_2^2  =  -(y·s)/(s·s)\n",
    "#   residual r_t = y_t + beta s_t\n",
    "#   V = Var_t(r_t)\n",
    "# ---------------------------------------------------------------------\n",
    "def resid_var_one(traj_i: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"\n",
    "    Residual variance for a single node time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj_i : np.ndarray (T,)\n",
    "        Time series of a single hub.\n",
    "    eps : float\n",
    "        Threshold to guard against division by zero in LS.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Variance of residuals r_t = y_t + beta s_t.\n",
    "    \"\"\"\n",
    "    x = traj_i[:-1]\n",
    "    y = moddiff(traj_i[1:] - doubling_vec(x))\n",
    "    s = Ih_vec(x)\n",
    "    denom = float(s @ s)\n",
    "    beta = 0.0 if denom < eps else -(y @ s) / denom\n",
    "    resid = y + beta * s\n",
    "    return float(np.var(resid))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Segment-level statistics for hubs:\n",
    "#   V_hat = mean residual variance across the two hubs,\n",
    "#   K_hat = mean of K(x_t) across the two hubs (i.e. empirical E K(x))\n",
    "# ---------------------------------------------------------------------\n",
    "def hub_stats_segment(traj: np.ndarray, seed: int = 0) -> Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute (V_hat, K_hat) for a single B/C candidate segment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray (N x T)\n",
    "        Segment trajectory.\n",
    "    seed : int\n",
    "        RNG seed used by GMM.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (V_hat, K_hat, hubs)\n",
    "        V_hat : float\n",
    "            Mean residual variance across the two hubs in the segment.\n",
    "        K_hat : float\n",
    "            Mean of K(x_t) across the two hubs (empirical expectation).\n",
    "        hubs : np.ndarray (size 2)\n",
    "            Indices of the two hubs.\n",
    "    \"\"\"\n",
    "    S = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S, seed=seed))[0]\n",
    "    if hubs.size != 2:\n",
    "        raise RuntimeError(\"This segment is not type B/C (number of hubs ≠ 2).\")\n",
    "    V_list, K_list = [], []\n",
    "    for i in hubs:\n",
    "        xi = traj[i]\n",
    "        V_list.append(resid_var_one(xi))\n",
    "        K_list.append(float(np.mean(K_vec(xi[:-1]))))  # empirical E[K(x)] along the hub\n",
    "    V_hat = float(np.mean(V_list))\n",
    "    K_hat = float(np.mean(K_list))\n",
    "    return V_hat, K_hat, hubs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Single-segment coarse classification: A vs (B/C)\n",
    "# ---------------------------------------------------------------------\n",
    "def classify_A_and_BC(traj: np.ndarray, N: int) -> str:\n",
    "    \"\"\"\n",
    "    Decide whether a single segment corresponds to A (one hub) or B/C (two hubs).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str : \"A_N\" or \"B_N and C_N\"\n",
    "    \"\"\"\n",
    "    S = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    return \"A_N\" if hubs.size == 1 else \"B_N and C_N\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Two-segment B vs C classifier via alpha^2-consistency\n",
    "#   For each segment s (s=1,2):\n",
    "#      - compute V_s and K_s from the hubs,\n",
    "#      - form S_{s,B} = F_B K_s, S_{s,C} = F_C K_s,\n",
    "#   Then compare the two hypotheses: (seg1=B, seg2=C) vs (seg1=C, seg2=B)\n",
    "#   by the log-mismatch of the implied alpha^2.\n",
    "# ---------------------------------------------------------------------\n",
    "def classify_B_vs_C_two_segments(\n",
    "    traj1: np.ndarray, traj2: np.ndarray, N: int, seed: int = 0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classify which of the two segments is B and which is C under the assumption\n",
    "    that both segments share the same (unknown) coupling strength alpha.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj1, traj2 : np.ndarray (N x T)\n",
    "        Two B/C candidate segments.\n",
    "    N : int\n",
    "        Number of nodes in the graph.\n",
    "    seed : int\n",
    "        RNG seeds used by the GMM calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the decision and useful diagnostics:\n",
    "          - 'label'      : 'first_is_B' or 'first_is_C'\n",
    "          - 'alpha2_BC'  : (alpha^2 estimate if seg1=B, seg2=C)\n",
    "          - 'alpha2_CB'  : (alpha^2 estimate if seg1=C, seg2=B)\n",
    "          - 'D_BC','D_CB': log-mismatches under the two hypotheses\n",
    "          - 'V1','K1','V2','K2'\n",
    "          - 'hubs1','hubs2'\n",
    "          - 'fac_B','fac_C' (the topology factors used)\n",
    "    \"\"\"\n",
    "    V1, K1, hubs1 = hub_stats_segment(traj1, seed=seed)\n",
    "    V2, K2, hubs2 = hub_stats_segment(traj2, seed=seed + 1)\n",
    "\n",
    "    # Topology factors d/Delta^2 (choose the convention you prefer).\n",
    "    # Here we use: B → 1/(N-2), C → 1/(N/2 - 1).\n",
    "    fac_B = 1.0 / (N - 2)\n",
    "    fac_C = 1.0 / (N // 2 - 1)\n",
    "\n",
    "    # Theoretical scalings without alpha^2\n",
    "    S1B, S1C = fac_B * K1, fac_C * K1\n",
    "    S2B, S2C = fac_B * K2, fac_C * K2\n",
    "\n",
    "    # Alpha^2 estimates under the two global assignments\n",
    "    a2_1_B, a2_2_C = V1 / S1B, V2 / S2C  # hypothesis: (seg1=B, seg2=C)\n",
    "    a2_1_C, a2_2_B = V1 / S1C, V2 / S2B  # hypothesis: (seg1=C, seg2=B)\n",
    "\n",
    "    # Log-mismatch of alpha^2 under each hypothesis\n",
    "    D_BC = abs(np.log(a2_1_B) - np.log(a2_2_C))\n",
    "    D_CB = abs(np.log(a2_1_C) - np.log(a2_2_B))\n",
    "\n",
    "    label = \"first_is_B\" if D_BC < D_CB else \"first_is_C\"\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"alpha2_BC\": (a2_1_B, a2_2_C),\n",
    "        \"alpha2_CB\": (a2_1_C, a2_2_B),\n",
    "        \"D_BC\": D_BC,\n",
    "        \"D_CB\": D_CB,\n",
    "        \"V1\": V1,\n",
    "        \"K1\": K1,\n",
    "        \"V2\": V2,\n",
    "        \"K2\": K2,\n",
    "        \"hubs1\": hubs1,\n",
    "        \"hubs2\": hubs2,\n",
    "        \"fac_B\": fac_B,\n",
    "        \"fac_C\": fac_C,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Demonstration\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    N, T, discard = 50, 8000, 800\n",
    "    alpha = \"0.25\"\n",
    "\n",
    "    # 1) Single-segment A vs (B/C)\n",
    "    for gname, maker in [(\"A_N\", graph_A), (\"B_N\", graph_B), (\"C_N\", graph_C)]:\n",
    "        traj = GraphSystemDecimal(maker(N), alpha=alpha, seed=hash(gname) % 2**32).run(\n",
    "            T, discard\n",
    "        )\n",
    "        print(f\"{gname}  → classify_ABC → {classify_A_and_BC(traj, N)}\")\n",
    "\n",
    "    # 2) Two segments: B vs C (alpha unknown but identical across segments)\n",
    "    trajB = GraphSystemDecimal(graph_B_like(N), alpha=alpha, seed=1).run(T, discard)\n",
    "    trajC = GraphSystemDecimal(graph_C_like(N), alpha=alpha, seed=2).run(T, discard)\n",
    "\n",
    "    out = classify_B_vs_C_two_segments(trajB, trajC, N)\n",
    "    print(\"\\nB/C decision:\", out[\"label\"])\n",
    "    print(\n",
    "        f\"D_BC={out['D_BC']:.3e} (seg1=B, seg2=C) | \"\n",
    "        f\"D_CB={out['D_CB']:.3e} (seg1=C, seg2=B)\"\n",
    "    )\n",
    "    print(f\"alpha^2 under (B,C) = {out['alpha2_BC']}\")\n",
    "    print(f\"alpha^2 under (C,B) = {out['alpha2_CB']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cdff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6222b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_N  → classify_ABC → A_N\n",
      "B_N  → classify_ABC → B_N and C_N\n",
      "C_N  → classify_ABC → B_N and C_N\n",
      "\n",
      "B/C decision: first_is_B\n",
      "D_BC=1.316e-02 (seg1=B, seg2=C) | D_CB=1.373e+00 (seg1=C, seg2=B)\n",
      "alpha^2 under (B,C) = (1.1972100698978247, 1.1815587706174113)\n",
      "alpha^2 under (C,B) = (0.5986050349489124, 2.3631175412348226)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# star_network_identify.py  (revised B/C decision via α²-consistency + hub empirical law)\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Callable, Tuple\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# ---------------- High precision core (unchanged except optional new coupling) ----------\n",
    "getcontext().prec = 200\n",
    "mp.mp.dps = getcontext().prec\n",
    "\n",
    "class GraphSystemDecimal:\n",
    "    def __init__(self, A: np.ndarray, alpha: str = '0.25',\n",
    "                 local_map: Callable[[Decimal], Decimal] | None = None,\n",
    "                 coupling_fn: Callable[[Decimal, Decimal], Decimal] | None = None,\n",
    "                 seed: int = 0):\n",
    "        self.A = np.asarray(A, dtype=float)\n",
    "        self.N = self.A.shape[0]\n",
    "        self.Delta = self.A.sum(axis=0).max()\n",
    "        self.alpha = Decimal(alpha)\n",
    "        self.local_map = local_map or (lambda x: (Decimal(2) * x) % 1)   # doubling\n",
    "        self.coupling = coupling_fn or coupling_sin_sin                   # NEW default\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def _coupling_term(self):\n",
    "        incr = [Decimal(0)] * self.N\n",
    "        for j in range(self.N):\n",
    "            if self.A[j].sum() == 0:\n",
    "                continue\n",
    "            for i in range(self.N):\n",
    "                if self.A[j, i]:\n",
    "                    incr[i] += self.coupling(self.x[j], self.x[i])\n",
    "        d = Decimal(str(self.Delta))\n",
    "        return [v / d for v in incr]\n",
    "\n",
    "    def step(self):\n",
    "        xn = [(Decimal(2) * x) % 1 for x in self.x]  # f(x)=2x mod 1\n",
    "        coup = self._coupling_term()\n",
    "        xn = [(xi + self.alpha * ci) % 1 for xi, ci in zip(xn, coup)]\n",
    "        self.x = xn\n",
    "        return xn\n",
    "\n",
    "    def reset(self):\n",
    "        self.x = [Decimal(str(v)) for v in self.rng.random(self.N)]\n",
    "\n",
    "    def run(self, T: int, discard: int = 0):\n",
    "        traj = np.zeros((self.N, max(0, T - discard)))\n",
    "        for k in range(T):\n",
    "            xt = self.step()\n",
    "            if k >= discard:\n",
    "                traj[:, k - discard] = [float(v) for v in xt]\n",
    "        return traj\n",
    "\n",
    "# ---------------- Graph generators (fix split bug in C) ---------------------\n",
    "def graph_A(N: int):\n",
    "    A = np.zeros((N, N))\n",
    "    A[np.arange(N - 1), N - 1] = 1\n",
    "    return A\n",
    "\n",
    "def graph_B(N: int):\n",
    "    A = np.zeros((N, N))\n",
    "    leaves = np.arange(N - 2)\n",
    "    A[leaves, N - 1] = 1\n",
    "    A[leaves, N - 2] = 1\n",
    "    return A\n",
    "\n",
    "def graph_C(N: int):\n",
    "    # leaves: 0..N-3 ; split evenly\n",
    "    A = np.zeros((N, N))\n",
    "    L = N - 2\n",
    "    half = L // 2\n",
    "    first = np.arange(0, half)\n",
    "    second = np.arange(half, L)\n",
    "    A[first,  N - 2] = 1\n",
    "    A[second, N - 1] = 1\n",
    "    return A\n",
    "\n",
    "# ---------------- Model-specific h, its integral and variance kernel --------\n",
    "# h(x,y) = 2 sin x sin y  (x,y ∈ [0,1) identified with the circle)\n",
    "def coupling_sin_sin(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "    v = 2.0 * float(mp.sin(mp.mpf(str(xs)))) * float(mp.sin(mp.mpf(str(xt))))\n",
    "    return Decimal(str(v))\n",
    "\n",
    "C1 = 2.0 * (1.0 - np.cos(1.0))                      # m_h(x) = C1 * sin x\n",
    "CK = (2.0 - np.sin(2.0)) - C1**2                     # K(x) = CK*sin^2 x\n",
    "\n",
    "def doubling_vec(u: np.ndarray) -> np.ndarray:\n",
    "    return (2.0 * u) % 1.0\n",
    "\n",
    "def Ih_vec(u: np.ndarray) -> np.ndarray:\n",
    "    return C1 * np.sin(u)\n",
    "\n",
    "def K_vec(u: np.ndarray) -> np.ndarray:\n",
    "    return CK * np.sin(u) ** 2\n",
    "\n",
    "# ---------------- Utilities: wrap, strength, GMM hubs -----------------------\n",
    "def moddiff(u):\n",
    "    return ((u + 0.5) % 1.0) - 0.5\n",
    "\n",
    "def compute_strength(traj: np.ndarray) -> np.ndarray:\n",
    "    x, x1 = traj[:, :-1], traj[:, 1:]\n",
    "    Delta = moddiff(x1 - doubling_vec(x))\n",
    "    return np.abs(Delta).mean(axis=1)\n",
    "\n",
    "def gmm_hubs(S, seed=0):\n",
    "    g = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    return g.predict(S.reshape(-1, 1)) == np.argmax(g.means_)\n",
    "\n",
    "# ---------------- Residual variance at one hub (regress on m_h) ------------\n",
    "def resid_var_one(traj_i: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    x = traj_i[:-1]\n",
    "    y = moddiff(traj_i[1:] - doubling_vec(x))\n",
    "    s = Ih_vec(x)\n",
    "    denom = float(s @ s)\n",
    "    beta = 0.0 if denom < eps else -(y @ s) / denom\n",
    "    resid = y + beta * s\n",
    "    return float(np.var(resid))\n",
    "\n",
    "# -------- Segment-level stats: use hub empirical law for K ------------------\n",
    "def hub_stats_segment(traj: np.ndarray, seed: int = 0) -> Tuple[float, float, np.ndarray]:\n",
    "    S    = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S, seed=seed))[0]\n",
    "    if hubs.size != 2:\n",
    "        raise RuntimeError(\"segment is not B/C type (number of hubs ≠ 2)\")\n",
    "    V_list, K_list = [], []\n",
    "    for i in hubs:\n",
    "        xi = traj[i]\n",
    "        V_list.append(resid_var_one(xi))\n",
    "        K_list.append(float(np.mean(K_vec(xi[:-1]))))  # <-- 经验分布进入 K 的期望\n",
    "    V_hat = float(np.mean(V_list))\n",
    "    K_hat = float(np.mean(K_list))\n",
    "    return V_hat, K_hat, hubs\n",
    "\n",
    "# ---------------- A vs (B/C) (保持不变) -------------------------------------\n",
    "def classify_A_and_BC(traj: np.ndarray, N: int) -> str:\n",
    "    S = compute_strength(traj)\n",
    "    hubs = np.where(gmm_hubs(S))[0]\n",
    "    return \"A_N\" if hubs.size == 1 else \"B_N and C_N\"\n",
    "\n",
    "# ---------------- B vs C：α²一致性（两段输入） -----------------------------\n",
    "def classify_B_vs_C_two_segments(traj1: np.ndarray, traj2: np.ndarray, N: int, seed: int = 0):\n",
    "    V1, K1, hubs1 = hub_stats_segment(traj1, seed=seed)\n",
    "    V2, K2, hubs2 = hub_stats_segment(traj2, seed=seed+1)\n",
    "\n",
    "    fac_B = 1.0 / (N - 2)          # d/Δ^2 for B\n",
    "    fac_C = 1.0 / (N // 2 - 1)     # d/Δ^2 for C\n",
    "\n",
    "    a2_1_B = V1 / (fac_B * K1)\n",
    "    a2_1_C = V1 / (fac_C * K1)\n",
    "    a2_2_B = V2 / (fac_B * K2)\n",
    "    a2_2_C = V2 / (fac_C * K2)\n",
    "\n",
    "    D_BC = abs(np.log(a2_1_B) - np.log(a2_2_C))   # seg1=B, seg2=C\n",
    "    D_CB = abs(np.log(a2_1_C) - np.log(a2_2_B))   # seg1=C, seg2=B\n",
    "    label = \"first_is_B\" if D_BC < D_CB else \"first_is_C\"\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"alpha2_BC\": (a2_1_B, a2_2_C),\n",
    "        \"alpha2_CB\": (a2_1_C, a2_2_B),\n",
    "        \"D_BC\": D_BC, \"D_CB\": D_CB,\n",
    "        \"V1\": V1, \"K1\": K1, \"V2\": V2, \"K2\": K2,\n",
    "        \"hubs1\": hubs1, \"hubs2\": hubs2,\n",
    "        \"fac_B\": fac_B, \"fac_C\": fac_C\n",
    "    }\n",
    "\n",
    "def coupling_modified(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "    \"\"\"\n",
    "    A modified coupling function h(x, y) = 2*sin(x)*sin(2*y), where x, y ∈ [0, 1).\n",
    "    This function is chosen to maximize the variance in hub nodes while complicating the correlation method.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    xs : Decimal\n",
    "        State value of node x.\n",
    "    xt : Decimal\n",
    "        State value of node y.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Decimal\n",
    "        The coupling term h(x, y).\n",
    "    \"\"\"\n",
    "    # u(x) = 2*sin(x), v(y) = sin(2*y)\n",
    "    u_x = 2.0 * mp.sin(TWOPI*mp.mpf(str(xs)))\n",
    "    v_y = mp.sin(2.0 * mp.mpf(str(xt)))\n",
    "    return Decimal(str(u_x * v_y))\n",
    "# ---------------- Demo ------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    N, T, discard = 50, 8000, 800\n",
    "    alpha = '0.25'\n",
    "\n",
    "    # 单段：A vs (B/C)\n",
    "    for gname, maker in [(\"A_N\", graph_A), (\"B_N\", graph_B), (\"C_N\", graph_C)]:\n",
    "        traj = GraphSystemDecimal(maker(N), alpha=alpha, seed=hash(gname) % 2**32).run(T, discard)\n",
    "        print(f\"{gname}  → classify_ABC → {classify_A_and_BC(traj, N)}\")\n",
    "\n",
    "    # 两段：B vs C（α未知但一致）\n",
    "    trajB = GraphSystemDecimal(graph_B(N), alpha=alpha, seed=1, coupling_fn=coupling_modified).run(T, discard)\n",
    "    trajC = GraphSystemDecimal(graph_C(N), alpha=alpha, seed=2,coupling_fn=coupling_modified).run(T, discard)\n",
    "\n",
    "    out = classify_B_vs_C_two_segments(trajB, trajC, N)\n",
    "    print(\"\\nB/C decision:\", out['label'])\n",
    "    print(f\"D_BC={out['D_BC']:.3e} (seg1=B, seg2=C) | D_CB={out['D_CB']:.3e} (seg1=C, seg2=B)\")\n",
    "    print(f\"alpha^2 under (B,C) = {out['alpha2_BC']}\")\n",
    "    print(f\"alpha^2 under (C,B) = {out['alpha2_CB']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d2e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a245482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorhthm 1.1（f is not know）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca0e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment A classified as: A_N | hubs: [39]\n",
      "Segment B classified as: B_N and C_N | hubs: [38 39]\n",
      "Segment C classified as: B_N and C_N | hubs: [38 39]\n",
      "A: f-hat(grid) head: [1.    0.125 0.25  0.375 0.5  ]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A vs (B/C) classification when the local map f is unknown,\n",
    "plus reconstruction of f from leaves, using Fourier (sin/cos) regression\n",
    "on the circle and hub detection by function dissimilarity.\n",
    "\n",
    "This module assumes you already have:\n",
    "  - GraphSystemDecimal (simulator),\n",
    "  - graph_A, graph_B, graph_C,\n",
    "  - coupling_sin_sin, etc.\n",
    "\n",
    "We add:\n",
    "  * Fourier design matrix builders (on [0, 1) with 2π angles),\n",
    "  * per-node circular regression (predict sin and cos of next angle),\n",
    "  * function evaluation on a grid and pairwise Pearson distances,\n",
    "  * hub detection by distance-sum scores S_i,\n",
    "  * A vs (B/C) decision from the hub count,\n",
    "  * reconstruction of f from leaves as a Fourier map  x -> x^+ (mod 1).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Any, Iterable\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "# ----------------------------- Utilities ------------------------------------\n",
    "def _angle(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Map x in [0,1) to 2πx angles.\"\"\"\n",
    "    return 2.0 * np.pi * u\n",
    "\n",
    "\n",
    "def fourier_design(x: np.ndarray, M: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a Fourier feature matrix Φ(x) = [cos(0*θ), cos(1*θ),...,cos(M*θ), sin(1*θ),...,sin(M*θ)],\n",
    "    where θ = 2πx.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray, shape (T,)\n",
    "        Inputs in [0,1).\n",
    "    M : int\n",
    "        Number of harmonics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Φ : np.ndarray, shape (T, 2M+1)\n",
    "        Columns: [cos0,...,cosM, sin1,...,sinM].\n",
    "        Note sin0 is identically 0 and omitted; cos0 = 1 is the intercept.\n",
    "    \"\"\"\n",
    "    theta = _angle(x)\n",
    "    T = x.shape[0]\n",
    "    # cos block: j = 0..M\n",
    "    cos_block = np.empty((T, M + 1))\n",
    "    for j in range(M + 1):\n",
    "        cos_block[:, j] = np.cos(j * theta)\n",
    "    # sin block: j = 1..M\n",
    "    sin_block = np.empty((T, M))\n",
    "    for j in range(1, M + 1):\n",
    "        sin_block[:, j - 1] = np.sin(j * theta)\n",
    "    return np.concatenate([cos_block, sin_block], axis=1)  # (T, 2M+1)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrigMap:\n",
    "    \"\"\"\n",
    "    A learned circular map represented by two linear models:\n",
    "       sin(2π x_next) ≈ Φ(x) @ w_s\n",
    "       cos(2π x_next) ≈ Φ(x) @ w_c\n",
    "    \"\"\"\n",
    "    M: int\n",
    "    w_s: np.ndarray  # shape (2M+1,)\n",
    "    w_c: np.ndarray  # shape (2M+1,)\n",
    "\n",
    "    def predict_sc(self, x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Predict sin and cos of the next angle for a batch of inputs in [0,1).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (s_pred, c_pred) : two arrays of shape (len(x),)\n",
    "        \"\"\"\n",
    "        Phi = fourier_design(x, self.M)\n",
    "        s_pred = Phi @ self.w_s\n",
    "        c_pred = Phi @ self.w_c\n",
    "        return s_pred, c_pred\n",
    "\n",
    "    def predict_next(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict next x in [0,1) by atan2 on predicted (sin, cos).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_next_pred : np.ndarray in [0,1)\n",
    "        \"\"\"\n",
    "        s_pred, c_pred = self.predict_sc(x)\n",
    "        ang = np.arctan2(s_pred, c_pred)  # (-pi, pi]\n",
    "        x_next = (ang / (2.0 * np.pi)) % 1.0\n",
    "        return x_next\n",
    "\n",
    "\n",
    "def fit_trig_map_for_node(x: np.ndarray, y: np.ndarray, M: int, ridge: float = 0.0) -> TrigMap:\n",
    "    \"\"\"\n",
    "    Fit a TrigMap for one node by linear least squares on Fourier features.\n",
    "\n",
    "    Targets are circular: we regress sin(2π y) and cos(2π y) separately on Φ(x).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (T-1,)\n",
    "        Inputs (current states).\n",
    "    y : (T-1,)\n",
    "        Outputs (next states).\n",
    "    M : int\n",
    "        Fourier order.\n",
    "    ridge : float\n",
    "        Optional L2-regularization strength (0.0 = ordinary least squares).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TrigMap\n",
    "    \"\"\"\n",
    "    Phi = fourier_design(x, M)            # (T-1, 2M+1)\n",
    "    s_tar = np.sin(_angle(y))             # (T-1,)\n",
    "    c_tar = np.cos(_angle(y))             # (T-1,)\n",
    "\n",
    "    if ridge > 0.0:\n",
    "        # Ridge: (Phi^T Phi + λ I) w = Phi^T target\n",
    "        G = Phi.T @ Phi + ridge * np.eye(Phi.shape[1])\n",
    "        w_s = np.linalg.solve(G, Phi.T @ s_tar)\n",
    "        w_c = np.linalg.solve(G, Phi.T @ c_tar)\n",
    "    else:\n",
    "        # Ordinary LS via lstsq (robust to mild collinearity)\n",
    "        w_s, *_ = np.linalg.lstsq(Phi, s_tar, rcond=None)\n",
    "        w_c, *_ = np.linalg.lstsq(Phi, c_tar, rcond=None)\n",
    "\n",
    "    return TrigMap(M=M, w_s=w_s, w_c=w_c)\n",
    "\n",
    "\n",
    "def fit_trig_map_per_node(traj: np.ndarray, M: int, ridge: float = 0.0) -> list[TrigMap]:\n",
    "    \"\"\"\n",
    "    Fit a TrigMap g_i for each node i from its trajectory x_i(t) -> x_i(t+1).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray, shape (N, T)\n",
    "    M : int\n",
    "        Fourier order.\n",
    "    ridge : float\n",
    "        Optional ridge regularization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models : list[TrigMap] of length N\n",
    "    \"\"\"\n",
    "    N, T = traj.shape\n",
    "    models: list[TrigMap] = []\n",
    "    for i in range(N):\n",
    "        x = traj[i, :-1]\n",
    "        y = traj[i,  1:]\n",
    "        models.append(fit_trig_map_for_node(x, y, M=M, ridge=ridge))\n",
    "    return models\n",
    "\n",
    "\n",
    "def evaluate_models_on_grid(models: list[TrigMap], G: int = 2048) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Evaluate each model (sin and cos) on a uniform grid of size G in [0,1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    V : np.ndarray, shape (N, 2G)\n",
    "        For node i, row i is [s_pred(grid), c_pred(grid)] concatenated.\n",
    "        We also L2-normalize per grid point to reduce amplitude effects.\n",
    "    \"\"\"\n",
    "    N = len(models)\n",
    "    grid = np.linspace(0.0, 1.0, G, endpoint=False)\n",
    "    V = np.zeros((N, 2 * G), dtype=float)\n",
    "    for i, m in enumerate(models):\n",
    "        s, c = m.predict_sc(grid)  # each shape (G,)\n",
    "        # Normalize (optional but helpful): project to unit circle per grid point\n",
    "        norm = np.sqrt(s * s + c * c) + 1e-12\n",
    "        s_n = s / norm\n",
    "        c_n = c / norm\n",
    "        V[i, :G] = s_n\n",
    "        V[i, G:] = c_n\n",
    "    return V\n",
    "\n",
    "\n",
    "def pearson_distance_matrix(V: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise Pearson distances on rows of V:\n",
    "        d(i,j) = 1 - corr(V_i, V_j).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    V : np.ndarray, shape (N, D)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dmat : np.ndarray, shape (N, N)\n",
    "        Symmetric with zeros on the diagonal.\n",
    "    \"\"\"\n",
    "    # Center columns\n",
    "    X = V - V.mean(axis=0, keepdims=True)      # (N, D)\n",
    "    # Row-wise norms\n",
    "    row_norm = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    Xn = X / row_norm\n",
    "    # Correlation matrix = Xn Xn^T\n",
    "    C = Xn @ Xn.T\n",
    "    # Distance = 1 - corr\n",
    "    Dmat = 1.0 - C\n",
    "    np.fill_diagonal(Dmat, 0.0)\n",
    "    return Dmat\n",
    "\n",
    "\n",
    "def hub_scores_from_distances(Dmat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Hub score S_i = sum_{j≠i} d(i,j): how dissimilar node i is from the rest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Dmat : np.ndarray, (N, N)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    S : np.ndarray, (N,)\n",
    "    \"\"\"\n",
    "    return Dmat.sum(axis=1)\n",
    "\n",
    "\n",
    "def detect_hubs_from_scores(S: np.ndarray, seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect hubs by a 2-component GMM on the scores S.\n",
    "    The component with the larger mean corresponds to \"hubs\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hubs_mask : np.ndarray of bool, shape (N,)\n",
    "    \"\"\"\n",
    "    gmm = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    labels = gmm.predict(S.reshape(-1, 1))\n",
    "    means = gmm.means_.flatten()\n",
    "    hub_label = np.argmax(means)\n",
    "    hubs_mask = (labels == hub_label)\n",
    "    return hubs_mask\n",
    "\n",
    "\n",
    "# ----------------------- Main: A vs (B/C) when f is unknown -----------------\n",
    "def classify_A_vs_BC_unknown_f(\n",
    "    traj: np.ndarray,\n",
    "    M: int = 10,\n",
    "    grid_size: int = 2048,\n",
    "    ridge: float = 0.0,\n",
    "    seed: int = 0,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classify a single segment as 'A_N' (one hub) or 'B_N and C_N' (two hubs)\n",
    "    when the local map f is unknown.\n",
    "\n",
    "    Pipeline:\n",
    "      1) Fit a circular Fourier map g_i for each node i: x_i(t) -> x_i(t+1).\n",
    "      2) Evaluate g_i on a grid and build vectors v_i = [sin_pred, cos_pred].\n",
    "      3) Build pairwise Pearson distance matrix and scores S_i (sum of distances).\n",
    "      4) GMM on S_i to detect the hub group (higher mean).\n",
    "      5) If |hubs|=1 → 'A_N'; if |hubs|=2 → 'B_N and C_N'.\n",
    "      6) Reconstruct f from leaves by pooling all leaf samples and refitting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray (N x T)\n",
    "        Node trajectories after transient removal.\n",
    "    M : int\n",
    "        Fourier order for the regression.\n",
    "    grid_size : int\n",
    "        Number of grid points for comparing functions.\n",
    "    ridge : float\n",
    "        Optional L2-regularization in the Fourier regression.\n",
    "    seed : int\n",
    "        Random seed for the GMM.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        - 'label'            : 'A_N' or 'B_N and C_N'\n",
    "        - 'hubs_idx'         : np.ndarray of hub indices\n",
    "        - 'leaves_idx'       : np.ndarray of leaf indices\n",
    "        - 'scores'           : np.ndarray of S_i\n",
    "        - 'distance_matrix'  : np.ndarray of Pearson distances\n",
    "        - 'models'           : list[TrigMap] per node\n",
    "        - 'f_hat'            : TrigMap fitted on leaves (reconstructed f)\n",
    "    \"\"\"\n",
    "    N, T = traj.shape\n",
    "\n",
    "    # (1) Per-node Fourier regression on the circle\n",
    "    models = fit_trig_map_per_node(traj, M=M, ridge=ridge)\n",
    "\n",
    "    # (2) Evaluate on grid and (3) distances + (4) scores\n",
    "    V = evaluate_models_on_grid(models, G=grid_size)  # (N, 2G)\n",
    "    Dmat = pearson_distance_matrix(V)                 # (N, N)\n",
    "    S = hub_scores_from_distances(Dmat)               # (N,)\n",
    "\n",
    "    # (4) Hub detection by GMM on scores\n",
    "    hubs_mask = detect_hubs_from_scores(S, seed=seed)\n",
    "    hubs_idx = np.where(hubs_mask)[0]\n",
    "    leaves_idx = np.where(~hubs_mask)[0]\n",
    "\n",
    "    # (5) Decision\n",
    "    label = \"A_N\" if hubs_idx.size == 1 else \"B_N and C_N\"\n",
    "\n",
    "    # (6) Reconstruct f from leaves (pool all leaf samples)\n",
    "    #     If (rarely) no leaves are detected, fall back to all non-hub nodes.\n",
    "    if leaves_idx.size == 0:\n",
    "        leaves_idx = np.setdiff1d(np.arange(N), hubs_idx)\n",
    "    x_pool = traj[leaves_idx, :-1].ravel()\n",
    "    y_pool = traj[leaves_idx,  1:].ravel()\n",
    "    f_hat = fit_trig_map_for_node(x_pool, y_pool, M=M, ridge=ridge)\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"hubs_idx\": hubs_idx,\n",
    "        \"leaves_idx\": leaves_idx,\n",
    "        \"scores\": S,\n",
    "        \"distance_matrix\": Dmat,\n",
    "        \"models\": models,\n",
    "        \"f_hat\": f_hat,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------- Optional: evaluator for reconstructed f -------------\n",
    "def evaluate_f_hat(f_hat: TrigMap, x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Evaluate the reconstructed local map \\hat f on inputs x in [0,1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_next_pred : np.ndarray in [0,1)\n",
    "    \"\"\"\n",
    "    return f_hat.predict_next(x)\n",
    "\n",
    "\n",
    "# ----------------------- Demo (if you want to test) -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example demo assuming you have GraphSystemDecimal, graph_A/B/C available\n",
    "    # and coupling_sin_sin (h = 2 sin x sin y). Here we just show usage.\n",
    "    from math import isfinite\n",
    "\n",
    "    N, T, discard = 40, 6000, 600\n",
    "    alpha = \"0.25\"\n",
    "\n",
    "    # Simulate one A, one B, one C segment (with known simulator but unknown f to the classifier)\n",
    "    gsA = GraphSystemDecimal(graph_A(N), alpha=alpha, seed=1)\n",
    "    trajA = gsA.run(T, discard)\n",
    "\n",
    "    gsB = GraphSystemDecimal(graph_B(N), alpha=alpha, seed=2)\n",
    "    trajB = gsB.run(T, discard)\n",
    "\n",
    "    gsC = GraphSystemDecimal(graph_C(N), alpha=alpha, seed=3)\n",
    "    trajC = gsC.run(T, discard)\n",
    "\n",
    "    # Classify A vs (B/C) with unknown f\n",
    "    outA = classify_A_vs_BC_unknown_f(trajA, M=10, grid_size=2048, seed=0)\n",
    "    print(\"Segment A classified as:\", outA[\"label\"], \"| hubs:\", outA[\"hubs_idx\"])\n",
    "\n",
    "    outB = classify_A_vs_BC_unknown_f(trajB, M=10, grid_size=2048, seed=0)\n",
    "    print(\"Segment B classified as:\", outB[\"label\"], \"| hubs:\", outB[\"hubs_idx\"])\n",
    "\n",
    "    outC = classify_A_vs_BC_unknown_f(trajC, M=10, grid_size=2048, seed=0)\n",
    "    print(\"Segment C classified as:\", outC[\"label\"], \"| hubs:\", outC[\"hubs_idx\"])\n",
    "\n",
    "    # Evaluate reconstructed f̂ from leaves on a grid (optional sanity check)\n",
    "    grid = np.linspace(0, 1, 16, endpoint=False)\n",
    "    fA_grid = evaluate_f_hat(outA[\"f_hat\"], grid)\n",
    "    print(\"A: f-hat(grid) head:\", fA_grid[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0f7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7b7c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A] label: A_N hubs: [49]\n",
      "[B] ABC: B/C BC: B_N rho: 0.412 hubs: [48 49]\n",
      "[C] ABC: B/C BC: C_N rho: 0.022 hubs: [48 49]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Algorithm 2.2 (Advisor's method):\n",
    "  - Step 1: Node-wise reduced dynamics via circular Fourier regression.\n",
    "  - Step 2: Hub detection by function dissimilarity (Pearson distance on grid),\n",
    "            reconstruction of f from leaves, and beta_j estimation for hubs.\n",
    "  - Step 3: B vs C by correlation of hub residuals (after removing f and beta*m_h).\n",
    "\n",
    "Coupling assumed separable: h(x,y) = u(x) v(y), with <v> != 0.\n",
    "Default instance: u(x)=2 sin(x), v(y)=sin(y), <v>=1 - cos(1).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Any, Iterable\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# --------------------- circular helpers (on [0,1)) --------------------------\n",
    "def _angle(u: np.ndarray) -> np.ndarray:\n",
    "    return 2.0 * np.pi * u\n",
    "\n",
    "def moddiff(u: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Wrap to (-0.5, 0.5] (difference on the circle).\"\"\"\n",
    "    return ((u + 0.5) % 1.0) - 0.5\n",
    "\n",
    "# --------------------- Fourier features & trig map --------------------------\n",
    "def fourier_design(x: np.ndarray, M: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Φ(x) = [cos(0θ), cos(1θ), ..., cos(Mθ), sin(1θ), ..., sin(Mθ)],  θ = 2πx.\n",
    "    Shape: (T, 2M+1)\n",
    "    \"\"\"\n",
    "    theta = _angle(x)\n",
    "    T = x.shape[0]\n",
    "    cos_block = np.empty((T, M + 1))\n",
    "    for j in range(M + 1):\n",
    "        cos_block[:, j] = np.cos(j * theta)\n",
    "    sin_block = np.empty((T, M))\n",
    "    for j in range(1, M + 1):\n",
    "        sin_block[:, j - 1] = np.sin(j * theta)\n",
    "    return np.concatenate([cos_block, sin_block], axis=1)\n",
    "\n",
    "@dataclass\n",
    "class TrigMap:\n",
    "    M: int\n",
    "    w_s: np.ndarray  # sin-weights\n",
    "    w_c: np.ndarray  # cos-weights\n",
    "\n",
    "    def predict_sc(self, x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        Phi = fourier_design(x, self.M)\n",
    "        return Phi @ self.w_s, Phi @ self.w_c\n",
    "\n",
    "    def predict_next(self, x: np.ndarray) -> np.ndarray:\n",
    "        s, c = self.predict_sc(x)\n",
    "        ang = np.arctan2(s, c)          # (-pi, pi]\n",
    "        return (ang / (2.0 * np.pi)) % 1.0\n",
    "\n",
    "def fit_trig_map_for_node(x: np.ndarray, y: np.ndarray, M: int, ridge: float = 0.0) -> TrigMap:\n",
    "    \"\"\"Fit sin(2πy), cos(2πy) ~ Φ(x) by LS (optional ridge).\"\"\"\n",
    "    Phi = fourier_design(x, M)\n",
    "    s_tar = np.sin(_angle(y))\n",
    "    c_tar = np.cos(_angle(y))\n",
    "    if ridge > 0.0:\n",
    "        G = Phi.T @ Phi + ridge * np.eye(Phi.shape[1])\n",
    "        w_s = np.linalg.solve(G, Phi.T @ s_tar)\n",
    "        w_c = np.linalg.solve(G, Phi.T @ c_tar)\n",
    "    else:\n",
    "        w_s, *_ = np.linalg.lstsq(Phi, s_tar, rcond=None)\n",
    "        w_c, *_ = np.linalg.lstsq(Phi, c_tar, rcond=None)\n",
    "    return TrigMap(M=M, w_s=w_s, w_c=w_c)\n",
    "\n",
    "def fit_trig_map_per_node(traj: np.ndarray, M: int, ridge: float = 0.0) -> list[TrigMap]:\n",
    "    \"\"\"Fit a TrigMap for every node from its own series.\"\"\"\n",
    "    N, T = traj.shape\n",
    "    models: list[TrigMap] = []\n",
    "    for i in range(N):\n",
    "        x = traj[i, :-1]\n",
    "        y = traj[i,  1:]\n",
    "        models.append(fit_trig_map_for_node(x, y, M=M, ridge=ridge))\n",
    "    return models\n",
    "\n",
    "# --------------------- function embedding & distances -----------------------\n",
    "def evaluate_models_on_grid(models: list[TrigMap], G: int = 2048) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each model, evaluate (sin_pred, cos_pred) on a grid and normalize per point.\n",
    "    Returns V ∈ R^{N×2G} for Pearson-correlation comparison.\n",
    "    \"\"\"\n",
    "    N = len(models)\n",
    "    grid = np.linspace(0.0, 1.0, G, endpoint=False)\n",
    "    V = np.zeros((N, 2 * G), dtype=float)\n",
    "    for i, m in enumerate(models):\n",
    "        s, c = m.predict_sc(grid)\n",
    "        norm = np.sqrt(s * s + c * c) + 1e-12\n",
    "        V[i, :G] = s / norm\n",
    "        V[i, G:] = c / norm\n",
    "    return V\n",
    "\n",
    "def pearson_distance_matrix(V: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"D(i,j) = 1 - corr(V_i, V_j).\"\"\"\n",
    "    X = V - V.mean(axis=0, keepdims=True)\n",
    "    norm = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    Xn = X / norm\n",
    "    C = Xn @ Xn.T\n",
    "    D = 1.0 - C\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def hub_scores_from_distances(D: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"S_i = sum_j D(i,j).\"\"\"\n",
    "    return D.sum(axis=1)\n",
    "\n",
    "def detect_hubs_from_scores(S: np.ndarray, seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"2-component GMM on scores; higher-mean component = hubs.\"\"\"\n",
    "    gmm = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    labels = gmm.predict(S.reshape(-1, 1))\n",
    "    hub_label = np.argmax(gmm.means_.flatten())\n",
    "    return labels == hub_label\n",
    "\n",
    "# --------------------- m_h(x) for separable coupling -----------------------\n",
    "# For h(x,y) = 2 sin(x) sin(y): u(x) = 2 sin(x), v(y)=sin(y), <v> = 1 - cos(1).\n",
    "C1 = 2.0 * (1.0 - np.cos(1.0))       # <v> * 2  (since u(x)=2 sin x)\n",
    "def m_h_vec(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"m_h(x) = <v> * u(x) = C1 * sin(x).\"\"\"\n",
    "    return C1 * np.sin(x)\n",
    "\n",
    "# --------------------- Algorithm 2.2 main routine --------------------------\n",
    "def algorithm_22_classify_and_reconstruct(\n",
    "    traj: np.ndarray,\n",
    "    M: int = 10,\n",
    "    grid_size: int = 2048,\n",
    "    ridge: float = 0.0,\n",
    "    tau: float = 0.4,\n",
    "    seed: int = 0,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Advisor's Algorithm 2.2:\n",
    "      - Fit g_i per node,\n",
    "      - detect hubs by function dissimilarity,\n",
    "      - reconstruct f from leaves,\n",
    "      - estimate beta_j for hubs,\n",
    "      - compute corr of hub residuals and decide B vs C.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : np.ndarray (N x T)\n",
    "    M : int\n",
    "        Fourier order for the regression.\n",
    "    grid_size : int\n",
    "        Grid size for function comparisons.\n",
    "    ridge : float\n",
    "        Ridge regularization for the regression (0 = OLS).\n",
    "    tau : float\n",
    "        Correlation threshold to decide B (rho >= tau) vs C.\n",
    "    seed : int\n",
    "        RNG seed for the GMM.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with:\n",
    "      'label_ABC'  : 'A_N' or 'B/C'\n",
    "      'label_BC'   : 'B_N' or 'C_N' (only if two hubs)\n",
    "      'hubs_idx'   : np.ndarray\n",
    "      'leaves_idx' : np.ndarray\n",
    "      'models'     : list[TrigMap]\n",
    "      'f_hat'      : TrigMap (reconstructed f)\n",
    "      'beta_hat'   : dict {hub_idx: beta}\n",
    "      'xi'         : dict {hub_idx: residual series}\n",
    "      'rho_hubs'   : float (corr of the two hub residuals)\n",
    "      'scores'     : np.ndarray (S_i)\n",
    "      'distance_matrix' : np.ndarray\n",
    "    \"\"\"\n",
    "    N, T = traj.shape\n",
    "\n",
    "    # Step 1: node-wise reduced dynamics\n",
    "    models = fit_trig_map_per_node(traj, M=M, ridge=ridge)\n",
    "\n",
    "    # Step 2: hub detection via function dissimilarity\n",
    "    V = evaluate_models_on_grid(models, G=grid_size)\n",
    "    Dmat = pearson_distance_matrix(V)\n",
    "    S = hub_scores_from_distances(Dmat)\n",
    "    hubs_mask = detect_hubs_from_scores(S, seed=seed)\n",
    "    hubs_idx = np.where(hubs_mask)[0]\n",
    "    leaves_idx = np.where(~hubs_mask)[0]\n",
    "\n",
    "    # A vs (B/C)\n",
    "    if hubs_idx.size == 1:\n",
    "        # Reconstruct f from leaves for completeness\n",
    "        if leaves_idx.size == 0:\n",
    "            leaves_idx = np.setdiff1d(np.arange(N), hubs_idx)\n",
    "        x_pool = traj[leaves_idx, :-1].ravel()\n",
    "        y_pool = traj[leaves_idx,  1:].ravel()\n",
    "        f_hat = fit_trig_map_for_node(x_pool, y_pool, M=M, ridge=ridge)\n",
    "        return {\n",
    "            \"label_ABC\": \"A_N\",\n",
    "            \"label_BC\": None,\n",
    "            \"hubs_idx\": hubs_idx,\n",
    "            \"leaves_idx\": leaves_idx,\n",
    "            \"models\": models,\n",
    "            \"f_hat\": f_hat,\n",
    "            \"beta_hat\": {},\n",
    "            \"xi\": {},\n",
    "            \"rho_hubs\": None,\n",
    "            \"scores\": S,\n",
    "            \"distance_matrix\": Dmat,\n",
    "        }\n",
    "\n",
    "    # Two hubs → B/C candidate\n",
    "    label_ABC = \"B/C\"\n",
    "    if leaves_idx.size == 0:\n",
    "        leaves_idx = np.setdiff1d(np.arange(N), hubs_idx)\n",
    "    x_pool = traj[leaves_idx, :-1].ravel()\n",
    "    y_pool = traj[leaves_idx,  1:].ravel()\n",
    "    f_hat = fit_trig_map_for_node(x_pool, y_pool, M=M, ridge=ridge)\n",
    "\n",
    "    # Estimate beta_j per hub and residual xi_j\n",
    "    beta_hat: Dict[int, float] = {}\n",
    "    xi: Dict[int, np.ndarray] = {}\n",
    "    for j in hubs_idx:\n",
    "        xj = traj[j, :-1]\n",
    "        yj = traj[j,  1:]\n",
    "        y = moddiff(yj - f_hat.predict_next(xj))  # residual after removing f-hat\n",
    "        s = m_h_vec(xj)                           # m_h(x) = <v> * u(x)\n",
    "        denom = float(s @ s) + 1e-12\n",
    "        beta = float((y @ s) / denom)\n",
    "        beta_hat[int(j)] = beta\n",
    "        xi[int(j)] = moddiff(yj - f_hat.predict_next(xj) - beta * 0.0)  # optional pure phase diff\n",
    "        # more faithful to model: remove beta * m_h(x)\n",
    "        xi[int(j)] = moddiff(yj - f_hat.predict_next(xj) - beta * (m_h_vec(xj) % 1.0))\n",
    "\n",
    "    # Corr of the two hub residuals\n",
    "    h1, h2 = int(hubs_idx[0]), int(hubs_idx[1])\n",
    "    v1 = xi[h1] - xi[h1].mean()\n",
    "    v2 = xi[h2] - xi[h2].mean()\n",
    "    denom = (np.linalg.norm(v1) * np.linalg.norm(v2)) + 1e-12\n",
    "    rho = float((v1 @ v2) / denom)\n",
    "\n",
    "    label_BC = \"B_N\" if rho >= tau else \"C_N\"\n",
    "\n",
    "    return {\n",
    "        \"label_ABC\": label_ABC,\n",
    "        \"label_BC\": label_BC,\n",
    "        \"hubs_idx\": hubs_idx,\n",
    "        \"leaves_idx\": leaves_idx,\n",
    "        \"models\": models,\n",
    "        \"f_hat\": f_hat,\n",
    "        \"beta_hat\": beta_hat,\n",
    "        \"xi\": xi,\n",
    "        \"rho_hubs\": rho,\n",
    "        \"scores\": S,\n",
    "        \"distance_matrix\": Dmat,\n",
    "    }\n",
    "\n",
    "def coupling_modified(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "    \"\"\"\n",
    "    A modified coupling function h(x, y) = 2*sin(x)*sin(2*y), where x, y ∈ [0, 1).\n",
    "    This function is chosen to maximize the variance in hub nodes while complicating the correlation method.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    xs : Decimal\n",
    "        State value of node x.\n",
    "    xt : Decimal\n",
    "        State value of node y.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Decimal\n",
    "        The coupling term h(x, y).\n",
    "    \"\"\"\n",
    "    # u(x) = 2*sin(x), v(y) = sin(2*y)\n",
    "    u_x = 2.0 * mp.sin(TWOPI*mp.mpf(str(xs)))+1\n",
    "    v_y = mp.sin(2.0 * mp.mpf(str(xt)))\n",
    "    return Decimal(str(u_x * v_y))\n",
    "# --------------------- Demo (requires your simulator) -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # The following demo assumes that GraphSystemDecimal, graph_A, graph_B, graph_C\n",
    "    # are defined elsewhere (as in your previous code). Replace with your imports.\n",
    "    try:\n",
    "        from __main__ import GraphSystemDecimal, graph_A, graph_B, graph_C\n",
    "    except Exception:\n",
    "        print(\"Load your simulator (GraphSystemDecimal) and graph generators before running the demo.\")\n",
    "        raise\n",
    "\n",
    "    N, T, discard = 50, 8000, 800\n",
    "    alpha = \"0.25\"\n",
    "    #coupling_fn=coupling_modified\n",
    "    # Simulate one segment for A, B, C\n",
    "    trajA = GraphSystemDecimal(graph_A(N), alpha=alpha, seed=1).run(T, discard)\n",
    "    trajB = GraphSystemDecimal(graph_B_like(N), alpha=alpha, seed=2).run(T, discard)\n",
    "    trajC = GraphSystemDecimal(graph_C_like(N), alpha=alpha, seed=3).run(T, discard)\n",
    "\n",
    "    # Run Algorithm 2.2\n",
    "    outA = algorithm_22_classify_and_reconstruct(trajA, M=10, tau=0.4, seed=0)\n",
    "    print(\"[A] label:\", outA[\"label_ABC\"], \"hubs:\", outA[\"hubs_idx\"])\n",
    "\n",
    "    outB = algorithm_22_classify_and_reconstruct(trajB, M=10, tau=0.4, seed=0)\n",
    "    print(\"[B] ABC:\", outB[\"label_ABC\"], \"BC:\", outB[\"label_BC\"], \"rho:\", f\"{outB['rho_hubs']:.3f}\",\n",
    "          \"hubs:\", outB[\"hubs_idx\"])\n",
    "\n",
    "    outC = algorithm_22_classify_and_reconstruct(trajC, M=10, tau=0.4, seed=0)\n",
    "    print(\"[C] ABC:\", outC[\"label_ABC\"], \"BC:\", outC[\"label_BC\"], \"rho:\", f\"{outC['rho_hubs']:.3f}\",\n",
    "          \"hubs:\", outC[\"hubs_idx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a294167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#完整对比系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73faf9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Case A: H0 = 2 sin(2πx) sin(2πy), f = doubling (μ = Lebesgue) ===\n",
      "pure/energy: first_is_B   corr-B: C_N   corr-C: C_N\n",
      "like/energy: first_is_B    corr-B: C_N    corr-C: C_N\n",
      "family/energy: first_is_C  corr-B: C_N  corr-C: C_N\n",
      "\n",
      "=== Case B: H1 = sin(2πx)*(1+0.5 sin(2πy)),  ∫u=0 (Lebesgue) → corr-method weak; f = doubling ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Unified system:\n",
    "  - Algorithm 1 (Hub + Energy 2.1): two segments, unknown f, general Lipschitz H.\n",
    "  - Algorithm 2 (Correlation 2.2): single segment, unknown f.\n",
    "  - Detection process over: pure B/C, B_like/C_like, B_family/C_family (robustness test).\n",
    "  - Multiple H variants; switch local map f (doubling / logistic) and its invariant measure.\n",
    "\n",
    "High-precision simulator uses Decimal + mpmath.\n",
    "Theoretical integrals m_h(x) and K(x) are computed by mpmath.quad against the invariant density of f.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "from decimal import Decimal, getcontext\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Global precision for Decimal / mpmath\n",
    "# =============================================================================\n",
    "getcontext().prec = 200\n",
    "mp.mp.dps = getcontext().prec\n",
    "TWOPI = 2 * mp.pi\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Local maps (Decimal)\n",
    "# =============================================================================\n",
    "def f_doubling_decimal(x: Decimal) -> Decimal:\n",
    "    \"\"\"f(x) = 2x mod 1 on the circle [0,1).\"\"\"\n",
    "    return (Decimal(2) * x) % 1\n",
    "\n",
    "def f_logistic_decimal(x: Decimal) -> Decimal:\n",
    "    \"\"\"f(x) = 4 x (1 - x) on [0,1], (no modulo).\"\"\"\n",
    "    x_mp = mp.mpf(str(x))\n",
    "    y = 4 * x_mp * (1 - x_mp)\n",
    "    y = 0 if y < 0 else (1 if y > 1 else y)\n",
    "    return Decimal(str(y))\n",
    "\n",
    "# Invariant densities (for theoretical integrals over Y)\n",
    "def mu_pdf_uniform(y: mp.mpf) -> mp.mpf:\n",
    "    \"\"\"Lebesgue density on [0,1]: 1.\"\"\"\n",
    "    return mp.mpf('1.0') if (0 <= y <= 1) else mp.mpf('0.0')\n",
    "\n",
    "def mu_pdf_logistic(y: mp.mpf) -> mp.mpf:\n",
    "    \"\"\"Invariant density of f(x)=4x(1-x): 1/(pi*sqrt(y(1-y))) on (0,1).\"\"\"\n",
    "    if y <= 0 or y >= 1:\n",
    "        return mp.mpf('0.0')\n",
    "    return 1 / (mp.pi * mp.sqrt(y * (1 - y)))\n",
    "\n",
    "# =============================================================================\n",
    "# 2. General H(x,y): (a) mp version for simulator; (b) float version for vector ops\n",
    "# =============================================================================\n",
    "# --- Examples of H (vectorizable float versions for integration) ---\n",
    "def H0_sin2pi_sin2pi(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    return 2.0 * np.sin(2*np.pi*x) * np.sin(2*np.pi*y)\n",
    "\n",
    "def H1_u_zero_mean(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    # u(x)=sin(2πx), v(y)=1 + 0.5 sin(2π y);  <u>=0 under Lebesgue\n",
    "    return np.sin(2*np.pi*x) * (1.0 + 0.5*np.sin(2*np.pi*y))\n",
    "\n",
    "def H2_u_zero_mean_plus_const(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    return H1_u_zero_mean(x, y) + 0.5\n",
    "\n",
    "def H3_additive(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    # H(x,y) = f1(x) + f2(y): good for energy method, weak for correlation method\n",
    "    return 0.8*np.cos(2*np.pi*x) + 0.3*np.sin(4*np.pi*y)\n",
    "\n",
    "# --- mp versions (for simulator coupling) generated from float-H ---\n",
    "def coupling_from_H_float(h_float: Callable[[np.ndarray, np.ndarray], np.ndarray]) -> Callable[[Decimal, Decimal], Decimal]:\n",
    "    \"\"\"\n",
    "    Wrap H_float(x_target, y_source) → coupling(xs, xt) used by simulator.\n",
    "    xs: source state (Decimal), xt: target state (Decimal).\n",
    "    \"\"\"\n",
    "    def _c(xs: Decimal, xt: Decimal) -> Decimal:\n",
    "        x = float(xt); y = float(xs)\n",
    "        return Decimal(str(h_float(np.array(x), np.array(y)).item()))\n",
    "    return _c\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Theoretical integrals m_h(x), K(x) under invariant density μ\n",
    "#    (mp.quad-based; robust for logistic density singularities)\n",
    "# =============================================================================\n",
    "def build_mh_and_K_mp(h_float: Callable[[np.ndarray, np.ndarray], np.ndarray],\n",
    "                      mu_pdf: Callable[[mp.mpf], mp.mpf]) -> tuple[\n",
    "                          Callable[[np.ndarray], np.ndarray], Callable[[np.ndarray], np.ndarray]\n",
    "                      ]:\n",
    "    \"\"\"\n",
    "    Construct m_h(x) = ∫ h(x,y) μ(dy),  K(x) = ∫ h(x,y)^2 μ(dy) - m_h(x)^2.\n",
    "    Implemented via mp.quad over y∈[0,1].\n",
    "    Returns numpy-vectorized callables m_h_vec(x_array), K_vec(x_array).\n",
    "    \"\"\"\n",
    "    def h_mp(x: mp.mpf, y: mp.mpf) -> mp.mpf:\n",
    "        # Call float function but cast back to mp (safe for integrand)\n",
    "        return mp.mpf(h_float(np.array(float(x)), np.array(float(y))).item())\n",
    "\n",
    "    def m_h_scalar(x: float) -> float:\n",
    "        f = lambda yy: h_mp(mp.mpf(x), yy) * mu_pdf(yy)\n",
    "        val = mp.quad(f, [0, 1])\n",
    "        return float(val)\n",
    "\n",
    "    def Eh2_scalar(x: float) -> float:\n",
    "        f2 = lambda yy: (h_mp(mp.mpf(x), yy) ** 2) * mu_pdf(yy)\n",
    "        val = mp.quad(f2, [0, 1])\n",
    "        return float(val)\n",
    "\n",
    "    def m_h_vec(x: np.ndarray) -> np.ndarray:\n",
    "        x = np.asarray(x).reshape(-1)\n",
    "        return np.array([m_h_scalar(float(xx)) for xx in x])\n",
    "\n",
    "    def K_vec(x: np.ndarray) -> np.ndarray:\n",
    "        x = np.asarray(x).reshape(-1)\n",
    "        mh = m_h_vec(x)\n",
    "        Eh2 = np.array([Eh2_scalar(float(xx)) for xx in x])\n",
    "        return Eh2 - mh**2\n",
    "\n",
    "    return m_h_vec, K_vec\n",
    "\n",
    "# =============================================================================\n",
    "# 4. High-precision simulator (Decimal + mp)\n",
    "# =============================================================================\n",
    "class GraphSystemDecimal:\n",
    "    \"\"\"\n",
    "    x_i(t+1) = f(x_i(t)) + (alpha/Delta) * sum_{j: A[j,i]=1} H(x_i(t), x_j(t))   (mod 1 iff f is mod 1)\n",
    "    We do NOT force modulo for logistic; leave dynamics to local_map.\n",
    "    \"\"\"\n",
    "    def __init__(self, A: np.ndarray, alpha: str,\n",
    "                 local_map: Callable[[Decimal], Decimal],\n",
    "                 coupling_fn: Callable[[Decimal, Decimal], Decimal],\n",
    "                 seed: int = 0):\n",
    "        self.A = np.asarray(A, dtype=float)\n",
    "        self.N = self.A.shape[0]\n",
    "        self.Delta = float(self.A.sum(axis=0).max())  # max in-degree\n",
    "        self.alpha = Decimal(alpha)\n",
    "        self.local_map = local_map\n",
    "        self.coupling = coupling_fn\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.x = [Decimal(str(v)) for v in self.rng.random(self.N)]\n",
    "\n",
    "    def _coupling_term(self) -> list[Decimal]:\n",
    "        inc = [Decimal(0)] * self.N\n",
    "        for j in range(self.N):\n",
    "            if self.A[j].sum() == 0:\n",
    "                continue\n",
    "            xj = self.x[j]\n",
    "            for i in range(self.N):\n",
    "                if self.A[j, i]:\n",
    "                    inc[i] += self.coupling(xj, self.x[i])\n",
    "        d = Decimal(str(self.Delta if self.Delta > 0 else 1.0))\n",
    "        return [v / d for v in inc]\n",
    "\n",
    "    def step(self) -> list[Decimal]:\n",
    "        xn = [self.local_map(x) for x in self.x]\n",
    "        coup = self._coupling_term()\n",
    "        xn = [ (xi + self.alpha * ci) % 1 if self.local_map is f_doubling_decimal else (xi + self.alpha * ci)\n",
    "               for xi, ci in zip(xn, coup) ]\n",
    "        # keep in [0,1]\n",
    "        xn = [ Decimal('0.0') if v < 0 else (Decimal('1.0') if v > 1 else v) for v in xn ]\n",
    "        self.x = xn\n",
    "        return xn\n",
    "\n",
    "    def run(self, T: int, discard: int) -> np.ndarray:\n",
    "        traj = np.zeros((self.N, max(0, T - discard)))\n",
    "        for k in range(T):\n",
    "            xt = self.step()\n",
    "            if k >= discard:\n",
    "                traj[:, k - discard] = [float(v) for v in xt]\n",
    "        return traj\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Star-like graphs: pure / like / family\n",
    "# =============================================================================\n",
    "def graph_A(N: int) -> np.ndarray:\n",
    "    A = np.zeros((N, N)); A[np.arange(N - 1), N - 1] = 1; return A\n",
    "\n",
    "def graph_B(N: int) -> np.ndarray:\n",
    "    A = np.zeros((N, N)); leaves = np.arange(N - 2)\n",
    "    A[leaves, N - 1] = 1; A[leaves, N - 2] = 1; return A\n",
    "\n",
    "def graph_C(N: int) -> np.ndarray:\n",
    "    A = np.zeros((N, N)); L = N - 2; half = L // 2\n",
    "    A[np.arange(0, half), N - 2] = 1; A[np.arange(half, L), N - 1] = 1; return A\n",
    "\n",
    "def graph_B_like(N: int) -> np.ndarray:\n",
    "    A = graph_B(N)\n",
    "    A_leaves = np.arange(0, max(0, int(N/3) - 2))\n",
    "    B_leaves = np.arange(int(2*N/3), N - 2)\n",
    "    if len(A_leaves) > 0: A[A_leaves, N - 1] = 0\n",
    "    if len(B_leaves) > 0: A[B_leaves, N - 2] = 0\n",
    "    return A\n",
    "\n",
    "def graph_C_like(N: int) -> np.ndarray:\n",
    "    return graph_C(N)\n",
    "\n",
    "def graph_B_family(N: int, p_common: float = 2/3, p_ll: float = 0.0, seed: int = 0) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = np.zeros((N, N)); L = N - 2; leaves = np.arange(L)\n",
    "    hubA, hubB = N - 2, N - 1\n",
    "    n_both = int(round(p_common * L)); n_both = max(0, min(L, n_both))\n",
    "    n_ex = L - n_both; n_a = n_ex // 2; n_b = n_ex - n_a\n",
    "    idx_both = leaves[:n_both]; idx_a = leaves[n_both:n_both+n_a]; idx_b = leaves[n_both+n_a:L]\n",
    "    if n_both > 0: A[idx_both, hubA] = 1; A[idx_both, hubB] = 1\n",
    "    if n_a > 0:    A[idx_a, hubA] = 1\n",
    "    if n_b > 0:    A[idx_b, hubB] = 1\n",
    "    if p_ll > 0:\n",
    "        M = (rng.random((L, L)) < p_ll).astype(float); np.fill_diagonal(M, 0.0)\n",
    "        A[:L, :L] = np.maximum(A[:L, :L], M)\n",
    "    return A\n",
    "\n",
    "def graph_C_family(N: int, p_ll: float = 0.0, seed: int = 0) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = graph_C(N); L = N - 2\n",
    "    if p_ll > 0:\n",
    "        M = (rng.random((L, L)) < p_ll).astype(float); np.fill_diagonal(M, 0.0)\n",
    "        A[:L, :L] = np.maximum(A[:L, :L], M)\n",
    "    return A\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Fourier regression for unknown f; hub detection via function dissimilarity\n",
    "# =============================================================================\n",
    "def fourier_design(x: np.ndarray, M: int) -> np.ndarray:\n",
    "    theta = 2.0 * np.pi * x; T = x.shape[0]\n",
    "    cos_block = np.empty((T, M+1))\n",
    "    for j in range(M+1): cos_block[:, j] = np.cos(j * theta)\n",
    "    sin_block = np.empty((T, M))\n",
    "    for j in range(1, M+1): sin_block[:, j-1] = np.sin(j * theta)\n",
    "    return np.concatenate([cos_block, sin_block], axis=1)\n",
    "\n",
    "@dataclass\n",
    "class TrigMap:\n",
    "    M: int\n",
    "    w_s: np.ndarray\n",
    "    w_c: np.ndarray\n",
    "    def predict_sc(self, x: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        Phi = fourier_design(x, self.M); return Phi @ self.w_s, Phi @ self.w_c\n",
    "    def predict_next(self, x: np.ndarray) -> np.ndarray:\n",
    "        s, c = self.predict_sc(x); ang = np.arctan2(s, c); return (ang / (2.0*np.pi)) % 1.0\n",
    "\n",
    "def fit_trig_map_for_node(x: np.ndarray, y: np.ndarray, M: int, ridge: float = 0.0) -> TrigMap:\n",
    "    Phi = fourier_design(x, M); s_tar = np.sin(2*np.pi*y); c_tar = np.cos(2*np.pi*y)\n",
    "    if ridge > 0.0:\n",
    "        G = Phi.T @ Phi + ridge * np.eye(Phi.shape[1])\n",
    "        w_s = np.linalg.solve(G, Phi.T @ s_tar); w_c = np.linalg.solve(G, Phi.T @ c_tar)\n",
    "    else:\n",
    "        w_s, *_ = np.linalg.lstsq(Phi, s_tar, rcond=None)\n",
    "        w_c, *_ = np.linalg.lstsq(Phi, c_tar, rcond=None)\n",
    "    return TrigMap(M, w_s, w_c)\n",
    "\n",
    "def fit_trig_map_per_node(traj: np.ndarray, M: int = 10, ridge: float = 0.0) -> list[TrigMap]:\n",
    "    N, T = traj.shape; models = []\n",
    "    for i in range(N):\n",
    "        x = traj[i, :-1]; y = traj[i, 1:]; models.append(fit_trig_map_for_node(x, y, M, ridge))\n",
    "    return models\n",
    "\n",
    "def function_embedding_on_grid(models: list[TrigMap], G: int = 2048) -> np.ndarray:\n",
    "    N = len(models); grid = np.linspace(0.0, 1.0, G, endpoint=False)\n",
    "    V = np.zeros((N, 2*G))\n",
    "    for i, m in enumerate(models):\n",
    "        s, c = m.predict_sc(grid); norm = np.sqrt(s*s + c*c) + 1e-12\n",
    "        V[i, :G] = s / norm; V[i, G:] = c / norm\n",
    "    return V\n",
    "\n",
    "def pearson_distance_matrix(V: np.ndarray) -> np.ndarray:\n",
    "    X = V - V.mean(axis=0, keepdims=True)\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)\n",
    "    C = Xn @ Xn.T; D = 1.0 - C; np.fill_diagonal(D, 0.0); return D\n",
    "\n",
    "def detect_hubs_by_models(traj: np.ndarray, M: int = 10, ridge: float = 0.0,\n",
    "                          grid_size: int = 2048, seed: int = 0) -> np.ndarray:\n",
    "    models = fit_trig_map_per_node(traj, M, ridge)\n",
    "    V = function_embedding_on_grid(models, grid_size)\n",
    "    D = pearson_distance_matrix(V)\n",
    "    S = D.sum(axis=1)\n",
    "    gmm = GaussianMixture(2, random_state=seed).fit(S.reshape(-1, 1))\n",
    "    hubs_mask = gmm.predict(S.reshape(-1, 1)) == np.argmax(gmm.means_)\n",
    "    hubs = np.where(hubs_mask)[0]\n",
    "    if hubs.size != 2:\n",
    "        # fallback: choose the two largest S\n",
    "        hubs = np.argsort(-S)[:2]\n",
    "    return hubs\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Algorithm 1 (Energy 2.1): two segments, unknown f, general H\n",
    "# =============================================================================\n",
    "def fit_f_from_leaves(traj: np.ndarray, hubs: np.ndarray, M: int = 10, ridge: float = 0.0) -> TrigMap:\n",
    "    leaves = np.setdiff1d(np.arange(traj.shape[0]), hubs)\n",
    "    if leaves.size == 0:  # degenerate; fallback to all nodes\n",
    "        leaves = np.arange(traj.shape[0])\n",
    "    x_pool = traj[leaves, :-1].ravel(); y_pool = traj[leaves, 1:].ravel()\n",
    "    return fit_trig_map_for_node(x_pool, y_pool, M, ridge)\n",
    "\n",
    "def moddiff(u: np.ndarray) -> np.ndarray:\n",
    "    return ((u + 0.5) % 1.0) - 0.5\n",
    "\n",
    "def resid_var_one(traj_i: np.ndarray, f_hat: TrigMap,\n",
    "                  m_h_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                  eps: float = 1e-12) -> float:\n",
    "    x = traj_i[:-1]; y = moddiff(traj_i[1:] - f_hat.predict_next(x))\n",
    "    s = m_h_vec(x); denom = float(s @ s)\n",
    "    beta = 0.0 if denom < eps else -(y @ s) / denom\n",
    "    resid = y + beta * s\n",
    "    return float(np.var(resid))\n",
    "\n",
    "def energy_hub_stats(traj: np.ndarray,\n",
    "                     m_h_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                     K_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                     M: int = 10, ridge: float = 0.0, seed: int = 0) -> tuple[float, float, np.ndarray]:\n",
    "    hubs = detect_hubs_by_models(traj, M=M, ridge=ridge, seed=seed)\n",
    "    f_hat = fit_f_from_leaves(traj, hubs, M=M, ridge=ridge)\n",
    "    V_list, K_list = [], []\n",
    "    for h in hubs:\n",
    "        xi = traj[h]\n",
    "        V_list.append(resid_var_one(xi, f_hat, m_h_vec))\n",
    "        K_list.append(float(np.mean(K_vec(xi[:-1]))))\n",
    "    return float(np.mean(V_list)), float(np.mean(K_list)), hubs\n",
    "\n",
    "def classify_B_vs_C_two_segments_energy(traj1: np.ndarray, traj2: np.ndarray, N: int,\n",
    "                                        m_h_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                                        K_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                                        M: int = 10, ridge: float = 0.0, seed: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    α^2-consistency under pure B/C topology factors:\n",
    "      fac_B = 1/(N-2),  fac_C = 1/(N/2 - 1)\n",
    "    \"\"\"\n",
    "    V1, K1, hubs1 = energy_hub_stats(traj1, m_h_vec, K_vec, M, ridge, seed)\n",
    "    V2, K2, hubs2 = energy_hub_stats(traj2, m_h_vec, K_vec, M, ridge, seed+1)\n",
    "    fac_B = 1.0 / (N - 2)\n",
    "    fac_C = 1.0 / (max(1, N // 2 - 1))\n",
    "    a2_1_B, a2_2_C = V1/(fac_B*K1), V2/(fac_C*K2)\n",
    "    a2_1_C, a2_2_B = V1/(fac_C*K1), V2/(fac_B*K2)\n",
    "    D_BC = abs(np.log(a2_1_B) - np.log(a2_2_C))\n",
    "    D_CB = abs(np.log(a2_1_C) - np.log(a2_2_B))\n",
    "    label = \"first_is_B\" if D_BC < D_CB else \"first_is_C\"\n",
    "    return {\"label\": label, \"alpha2_BC\": (a2_1_B, a2_2_C), \"alpha2_CB\": (a2_1_C, a2_2_B),\n",
    "            \"D_BC\": D_BC, \"D_CB\": D_CB, \"V1\": V1, \"K1\": K1, \"V2\": V2, \"K2\": K2,\n",
    "            \"hubs1\": hubs1, \"hubs2\": hubs2, \"fac_B\": fac_B, \"fac_C\": fac_C}\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Algorithm 2 (Correlation 2.2): single segment, unknown f, general H\n",
    "# =============================================================================\n",
    "def corr_method_single_segment(traj: np.ndarray,\n",
    "                               m_h_vec: Callable[[np.ndarray], np.ndarray],\n",
    "                               tau: float = 0.4, M: int = 10, ridge: float = 0.0, seed: int = 0) -> Dict[str, Any]:\n",
    "    hubs = detect_hubs_by_models(traj, M=M, ridge=ridge, seed=seed)\n",
    "    leaves = np.setdiff1d(np.arange(traj.shape[0]), hubs)\n",
    "    f_hat = fit_f_from_leaves(traj, hubs, M=M, ridge=ridge)\n",
    "    # residuals per hub\n",
    "    xi: Dict[int, np.ndarray] = {}\n",
    "    for h in hubs:\n",
    "        xh = traj[h, :-1]; yh = traj[h, 1:]\n",
    "        y = moddiff(yh - f_hat.predict_next(xh))\n",
    "        s = m_h_vec(xh); denom = float(s @ s) + 1e-12\n",
    "        beta = float((y @ s) / denom)\n",
    "        xi[h] = moddiff(yh - f_hat.predict_next(xh) - beta * m_h_vec(xh))\n",
    "    # correlation\n",
    "    h1, h2 = hubs[0], hubs[1]\n",
    "    v1 = xi[h1] - xi[h1].mean(); v2 = xi[h2] - xi[h2].mean()\n",
    "    rho = float((v1 @ v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-12))\n",
    "    label_BC = \"B_N\" if rho >= tau else \"C_N\"\n",
    "    return {\"label_ABC\": \"B/C\", \"label_BC\": label_BC, \"rho_hubs\": rho,\n",
    "            \"hubs_idx\": hubs, \"leaves_idx\": leaves}\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Detection process (pure, like, family) without telling the algorithms\n",
    "# =============================================================================\n",
    "def simulate_segment(A: np.ndarray, alpha: str,\n",
    "                     local_map: Callable[[Decimal], Decimal],\n",
    "                     coupling: Callable[[Decimal, Decimal], Decimal],\n",
    "                     T: int, discard: int, seed: int) -> np.ndarray:\n",
    "    sys = GraphSystemDecimal(A, alpha=alpha, local_map=local_map, coupling_fn=coupling, seed=seed)\n",
    "    return sys.run(T, discard)\n",
    "\n",
    "def detection_process(N: int, T: int, discard: int, alpha: str,\n",
    "                      f_mode: str,\n",
    "                      h_float: Callable[[np.ndarray, np.ndarray], np.ndarray],\n",
    "                      mu_pdf: Callable[[mp.mpf], mp.mpf],\n",
    "                      tau: float = 0.4,\n",
    "                      p_common_B: float = 2/3, p_ll: float = 0.02,\n",
    "                      seed_base: int = 1) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run:\n",
    "      - pure B vs pure C (two segments) → energy 2.1; and 2.2 on each;\n",
    "      - B_like vs C_like (two segments) → energy 2.1; and 2.2 on each;\n",
    "      - B_family vs C_family (two segments) → energy 2.1; and 2.2 on each.\n",
    "    \"\"\"\n",
    "    # choose local map & invariant pdf\n",
    "    if f_mode == \"doubling\":\n",
    "        local_map = f_doubling_decimal\n",
    "    elif f_mode == \"logistic\":\n",
    "        local_map = f_logistic_decimal\n",
    "    else:\n",
    "        raise ValueError(\"f_mode must be 'doubling' or 'logistic'.\")\n",
    "\n",
    "    # build m_h, K and coupling from H\n",
    "    m_h_vec, K_vec = build_mh_and_K_mp(h_float, mu_pdf)\n",
    "    coupling = coupling_from_H_float(h_float)\n",
    "\n",
    "    results: Dict[str, Any] = {}\n",
    "\n",
    "    # ---- (1) pure B / pure C ----\n",
    "    A_B = graph_B(N); A_C = graph_C(N)\n",
    "    trajB = simulate_segment(A_B, alpha, local_map, coupling, T, discard, seed_base+10)\n",
    "    trajC = simulate_segment(A_C, alpha, local_map, coupling, T, discard, seed_base+20)\n",
    "\n",
    "    res_energy_pure = classify_B_vs_C_two_segments_energy(trajB, trajC, N, m_h_vec, K_vec, seed=seed_base)\n",
    "    res_corr_B_pure = corr_method_single_segment(trajB, m_h_vec, tau=tau, seed=seed_base+1)\n",
    "    res_corr_C_pure = corr_method_single_segment(trajC, m_h_vec, tau=tau, seed=seed_base+2)\n",
    "    results[\"pure\"] = {\"energy\": res_energy_pure, \"corr_B\": res_corr_B_pure, \"corr_C\": res_corr_C_pure}\n",
    "\n",
    "    # ---- (2) B_like / C_like ----\n",
    "    A_Bl = graph_B_like(N); A_Cl = graph_C_like(N)\n",
    "    trajBl = simulate_segment(A_Bl, alpha, local_map, coupling, T, discard, seed_base+30)\n",
    "    trajCl = simulate_segment(A_Cl, alpha, local_map, coupling, T, discard, seed_base+40)\n",
    "\n",
    "    res_energy_like = classify_B_vs_C_two_segments_energy(trajBl, trajCl, N, m_h_vec, K_vec, seed=seed_base+3)\n",
    "    res_corr_Bl = corr_method_single_segment(trajBl, m_h_vec, tau=tau, seed=seed_base+4)\n",
    "    res_corr_Cl = corr_method_single_segment(trajCl, m_h_vec, tau=tau, seed=seed_base+5)\n",
    "    results[\"like\"] = {\"energy\": res_energy_like, \"corr_B\": res_corr_Bl, \"corr_C\": res_corr_Cl}\n",
    "\n",
    "    # ---- (3) B_family / C_family ----\n",
    "    A_Bf = graph_B_family(N, p_common=p_common_B, p_ll=p_ll, seed=seed_base+50)\n",
    "    A_Cf = graph_C_family(N, p_ll=p_ll, seed=seed_base+60)\n",
    "    trajBf = simulate_segment(A_Bf, alpha, local_map, coupling, T, discard, seed_base+51)\n",
    "    trajCf = simulate_segment(A_Cf, alpha, local_map, coupling, T, discard, seed_base+61)\n",
    "\n",
    "    res_energy_fam = classify_B_vs_C_two_segments_energy(trajBf, trajCf, N, m_h_vec, K_vec, seed=seed_base+6)\n",
    "    res_corr_Bf = corr_method_single_segment(trajBf, m_h_vec, tau=tau, seed=seed_base+7)\n",
    "    res_corr_Cf = corr_method_single_segment(trajCf, m_h_vec, tau=tau, seed=seed_base+8)\n",
    "    results[\"family\"] = {\"energy\": res_energy_fam, \"corr_B\": res_corr_Bf, \"corr_C\": res_corr_Cf}\n",
    "\n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# 10. Demo runner: run full suites across several H/f combinations\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Common sim params\n",
    "    N, T, discard = 60, 8000, 800\n",
    "    alpha = \"0.25\"\n",
    "    tau = 0.40\n",
    "    p_common_B, p_ll = 2/3, 0.02\n",
    "\n",
    "    print(\"\\n=== Case A: H0 = 2 sin(2πx) sin(2πy), f = doubling (μ = Lebesgue) ===\")\n",
    "    out_A = detection_process(\n",
    "        N, T, discard, alpha,\n",
    "        f_mode=\"doubling\",\n",
    "        h_float=H0_sin2pi_sin2pi,\n",
    "        mu_pdf=mu_pdf_uniform,\n",
    "        tau=tau, p_common_B=p_common_B, p_ll=p_ll, seed_base=1\n",
    "    )\n",
    "    print(\"pure/energy:\", out_A[\"pure\"][\"energy\"][\"label\"], \"  corr-B:\", out_A[\"pure\"][\"corr_B\"][\"label_BC\"], \"  corr-C:\", out_A[\"pure\"][\"corr_C\"][\"label_BC\"])\n",
    "    print(\"like/energy:\", out_A[\"like\"][\"energy\"][\"label\"], \"   corr-B:\", out_A[\"like\"][\"corr_B\"][\"label_BC\"], \"   corr-C:\", out_A[\"like\"][\"corr_C\"][\"label_BC\"])\n",
    "    print(\"family/energy:\", out_A[\"family\"][\"energy\"][\"label\"], \" corr-B:\", out_A[\"family\"][\"corr_B\"][\"label_BC\"], \" corr-C:\", out_A[\"family\"][\"corr_C\"][\"label_BC\"])\n",
    "\n",
    "    print(\"\\n=== Case B: H1 = sin(2πx)*(1+0.5 sin(2πy)),  ∫u=0 (Lebesgue) → corr-method weak; f = doubling ===\")\n",
    "    out_B = detection_process(\n",
    "        N, T, discard, alpha,\n",
    "        f_mode=\"doubling\",\n",
    "        h_float=H1_u_zero_mean,\n",
    "        mu_pdf=mu_pdf_uniform,\n",
    "        tau=tau, p_common_B=p_common_B, p_ll=p_ll, seed_base=101\n",
    "    )\n",
    "    print(\"pure/energy:\", out_B[\"pure\"][\"energy\"][\"label\"], \"  corr-B:\", out_B[\"pure\"][\"corr_B\"][\"label_BC\"], \"  corr-C:\", out_B[\"pure\"][\"corr_C\"][\"label_BC\"])\n",
    "\n",
    "    print(\"\\n=== Case C: H2 = H1 + 0.5 (constant offset),  f = doubling ===\")\n",
    "    out_C = detection_process(\n",
    "        N, T, discard, alpha,\n",
    "        f_mode=\"doubling\",\n",
    "        h_float=H2_u_zero_mean_plus_const,\n",
    "        mu_pdf=mu_pdf_uniform,\n",
    "        tau=tau, p_common_B=p_common_B, p_ll=p_ll, seed_base=201\n",
    "    )\n",
    "    print(\"pure/energy:\", out_C[\"pure\"][\"energy\"][\"label\"], \"  corr-B:\", out_C[\"pure\"][\"corr_B\"][\"label_BC\"], \"  corr-C:\", out_C[\"pure\"][\"corr_C\"][\"label_BC\"])\n",
    "\n",
    "    print(\"\\n=== Case D: Switch f to logistic (μ = logistic density). With H1 (∫u=0 under Lebesgue but not under logistic) → corr-method recovers ===\")\n",
    "    out_D = detection_process(\n",
    "        N, T, discard, alpha,\n",
    "        f_mode=\"logistic\",\n",
    "        h_float=H1_u_zero_mean,           # the same H1, but μ changes\n",
    "        mu_pdf=mu_pdf_logistic,           # integrate against logistic invariant density\n",
    "        tau=tau, p_common_B=p_common_B, p_ll=p_ll, seed_base=301\n",
    "    )\n",
    "    print(\"pure/energy:\", out_D[\"pure\"][\"energy\"][\"label\"], \"  corr-B:\", out_D[\"pure\"][\"corr_B\"][\"label_BC\"], \"  corr-C:\", out_D[\"pure\"][\"corr_C\"][\"label_BC\"])\n",
    "\n",
    "    print(\"\\n=== Case E: Additive H3 = f1(x)+f2(y), f = doubling (good for energy, weak for correlation) ===\")\n",
    "    out_E = detection_process(\n",
    "        N, T, discard, alpha,\n",
    "        f_mode=\"doubling\",\n",
    "        h_float=H3_additive,\n",
    "        mu_pdf=mu_pdf_uniform,\n",
    "        tau=tau, p_common_B=p_common_B, p_ll=p_ll, seed_base=401\n",
    "    )\n",
    "    print(\"pure/energy:\", out_E[\"pure\"][\"energy\"][\"label\"], \"  corr-B:\", out_E[\"pure\"][\"corr_B\"][\"label_BC\"], \"  corr-C:\", out_E[\"pure\"][\"corr_C\"][\"label_BC\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988aa002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
